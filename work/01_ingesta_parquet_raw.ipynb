{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faf7c15c-6067-4f74-b3d6-bf62b153bc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in /opt/conda/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.11/site-packages (13.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (41.0.4)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (23.2.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2023.3.post1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (23.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (4.8.0)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.20.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.11.0)\n",
      "Requirement already satisfied: tomlkit in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (0.13.3)\n",
      "Requirement already satisfied: boto3>=1.24 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (1.40.55)\n",
      "Requirement already satisfied: botocore>=1.24 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (1.40.55)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.11/site-packages (from pyarrow) (1.24.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.24->snowflake-connector-python) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.24->snowflake-connector-python) (0.14.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.1.0->snowflake-connector-python) (1.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.1.0->snowflake-connector-python) (2.21)\n",
      "================================================================================\n",
      "Paquetes instalados correctamente.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Instalar las librerías necesarias para conectar Spark con Snowflake y manejar archivos Parquet desde fuentes HTTP.\n",
    "\n",
    "!pip install snowflake-connector-python pyarrow requests pandas\n",
    "print(\"=\" * 80)\n",
    "print(\"Paquetes instalados correctamente.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b675cdc-5681-49f6-8112-0b2440efdfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONFIGURACIÓN DE AMBIENTE - PROYECTO 3\n",
      "================================================================================\n",
      "Todas las variables de ambiente requeridas están configuradas.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verificar que todas las variables de ambiente necesarias estén configuradas.\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import snowflake.connector\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CONFIGURACIÓN DE AMBIENTE - PROYECTO 3\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Variables obligatorias de Snowflake\n",
    "required_vars = [\n",
    "    'SNOWFLAKE_ACCOUNT',\n",
    "    'SNOWFLAKE_DATABASE', \n",
    "    'SNOWFLAKE_SCHEMA_RAW',\n",
    "    'SNOWFLAKE_WAREHOUSE',\n",
    "    'SNOWFLAKE_USER',\n",
    "    'SNOWFLAKE_PASSWORD',\n",
    "    'SNOWFLAKE_ROLE'\n",
    "]\n",
    "\n",
    "# Verificar que todas las variables existan\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    print(f\"ERROR: Faltan variables de ambiente: {', '.join(missing_vars)}\")\n",
    "    print(\"Por favor configura tu archivo .env correctamente.\")\n",
    "else:\n",
    "    print(\"Todas las variables de ambiente requeridas están configuradas.\")\n",
    "    \n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac6e9a31-351b-4780-933f-32670cb0c415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SPARK SESSION CREADA EXITOSAMENTE\n",
      "================================================================================\n",
      "Spark Version: 3.5.0\n",
      "Spark UI disponible en: http://localhost:4040\n",
      "Timezone configurado: UTC\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Configurar Spark para:\n",
    "# 1. Conectarse a Snowflake mediante JDBC.\n",
    "# 2. Manejar timestamps en UTC (zona horaria consistente).\n",
    "# 3. Procesar archivos Parquet eficientemente.\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"P3 - Ingesta RAW - NYC Taxis - Anahi Andrade\")\n",
    "    \n",
    "    # Configuración de zona horaria para timestamps\n",
    "    .config(\"spark.sql.timestampType\", \"TIMESTAMP_LTZ\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    \n",
    "    # JARs necesarios para conectar Spark con Snowflake\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"net.snowflake:snowflake-jdbc:3.13.33,\"\n",
    "        \"net.snowflake:spark-snowflake_2.12:2.9.3-spark_3.1\"\n",
    "    )\n",
    "    \n",
    "    # Desactivar lectura vectorizada para mayor compatibilidad\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "    \n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SPARK SESSION CREADA EXITOSAMENTE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Spark UI disponible en: http://localhost:4040\")\n",
    "print(f\"Timezone configurado: {spark.conf.get('spark.sql.session.timeZone')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f396160c-1d59-465c-829b-ae0cad145bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Sistema de checkpoint configurado.\n",
      "Archivo checkpoint: /home/jovyan/work/checkpoint_ingesta.json\n",
      "Opciones de conexión Snowflake configuradas.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Definir:\n",
    "# 1. Opciones de conexión a Snowflake para Spark.\n",
    "# 2. Sistema de checkpoint para idempotencia (no duplicar cargas).\n",
    "\n",
    "# Configuración de conexión Snowflake para Spark DataFrame Writer\n",
    "snowflake_options = {\n",
    "    \"sfURL\": f\"{os.getenv('SNOWFLAKE_ACCOUNT')}.snowflakecomputing.com\",\n",
    "    \"sfUser\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"sfPassword\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"sfDatabase\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"sfSchema\": os.getenv(\"SNOWFLAKE_SCHEMA_RAW\"),\n",
    "    \"sfWarehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    \"sfRole\": os.getenv(\"SNOWFLAKE_ROLE\")\n",
    "}\n",
    "\n",
    "# SISTEMA DE CHECKPOINT PARA IDEMPOTENCIA:\n",
    "# - Archivo JSON que registra qué meses ya fueron procesados exitosamente.\n",
    "# - Evita duplicar datos si el notebook se ejecuta múltiples veces.\n",
    "CHECKPOINT_FILE = \"/home/jovyan/work/checkpoint_ingesta.json\"\n",
    "\n",
    "def save_checkpoint(service, year, month):\n",
    "    \n",
    "    # Guarda un checkpoint indicando que un mes específico fue procesado exitosamente.\n",
    "    # Args:\n",
    "    #   - service: Tipo de servicio ('yellow' o 'green')\n",
    "    #   - year: Año procesado\n",
    "    #   - month: Mes procesado (1-12)\n",
    "    checkpoint = {}\n",
    "    \n",
    "    # Cargar checkpoints existentes si el archivo existe\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "    \n",
    "    # Crear clave única para este mes/servicio\n",
    "    key = f\"{service}_{year}_{month:02d}\"\n",
    "    \n",
    "    # Guardar información del checkpoint\n",
    "    checkpoint[key] = {\n",
    "        \"service\": service,\n",
    "        \"year\": year,\n",
    "        \"month\": month,\n",
    "        \"processed_at\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # Escribir archivo actualizado\n",
    "    with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "        json.dump(checkpoint, f, indent=2)\n",
    "    \n",
    "    print(f\" Checkpoint guardado: {key}\")\n",
    "\n",
    "def load_checkpoint():\n",
    "    \n",
    "    # Carga el archivo de checkpoints existente.\n",
    "    # Returns:\n",
    "    #    - dict: Diccionario con todos los checkpoints guardados\n",
    "    \n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def is_processed(checkpoint, service, year, month):\n",
    "    \n",
    "    # Verifica si un mes ya fue procesado anteriormente.    \n",
    "    # Args:\n",
    "    #    - checkpoint: Diccionario de checkpoints cargado\n",
    "    #    - service: Tipo de servicio ('yellow' o 'green')\n",
    "    #    - year: Año a verificar\n",
    "    #    - month: Mes a verificar (1-12)\n",
    "    # Returns:\n",
    "    #    - bool: True si ya fue procesado, False si necesita procesarse\n",
    "    \n",
    "    key = f\"{service}_{year}_{month:02d}\"\n",
    "    return key in checkpoint\n",
    "print(\"=\" * 80)\n",
    "print(\"Sistema de checkpoint configurado.\")\n",
    "print(f\"Archivo checkpoint: {CHECKPOINT_FILE}\")\n",
    "print(\"Opciones de conexión Snowflake configuradas.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04d6bb73-1534-4053-a433-84b4cd209b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREACIÓN DE TABLAS RAW EN SNOWFLAKE\n",
      "================================================================================\n",
      "Creando tabla RAW_YELLOW_TRIPS...\n",
      "- Tabla RAW_YELLOW_TRIPS creada/verificada.\n",
      "\n",
      "Creando tabla RAW_GREEN_TRIPS...\n",
      "- Tabla RAW_GREEN_TRIPS creada/verificada.\n",
      "\n",
      "Creando tabla INGESTA_AUDIT...\n",
      "- Tabla INGESTA_AUDIT creada/verificada.\n",
      "================================================================================\n",
      "TODAS LAS TABLAS RAW CREADAS EXITOSAMENTE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Crear las tablas necesarias en Snowflake:\n",
    "# 1. RAW_YELLOW_TRIPS: Tabla espejo para datos de taxis amarillos.\n",
    "# 2. RAW_GREEN_TRIPS: Tabla espejo para datos de taxis verdes.\n",
    "# 3. INGESTA_AUDIT: Tabla de auditoría para rastrear todas las cargas.\n",
    "\n",
    "# Establecer conexión directa a Snowflake para ejecutar DDL\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.environ[\"SNOWFLAKE_USER\"],\n",
    "    password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "    account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "    database=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    schema=os.environ[\"SNOWFLAKE_SCHEMA_RAW\"],\n",
    "    role=os.environ[\"SNOWFLAKE_ROLE\"]\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CREACIÓN DE TABLAS RAW EN SNOWFLAKE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# TABLA RAW PARA YELLOW TAXIS:\n",
    "# - Estructura espejo del Parquet origen + metadatos de ingesta\n",
    "create_yellow_raw = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS RAW_YELLOW_TRIPS (\n",
    "    -- Campos originales del dataset NYC TLC Yellow\n",
    "    VENDORID BIGINT,\n",
    "    TPEP_PICKUP_DATETIME TIMESTAMP_NTZ,    -- Timestamp sin zona horaria\n",
    "    TPEP_DROPOFF_DATETIME TIMESTAMP_NTZ,\n",
    "    PASSENGER_COUNT DOUBLE,\n",
    "    TRIP_DISTANCE DOUBLE,\n",
    "    RATECODEID DOUBLE,\n",
    "    STORE_AND_FWD_FLAG VARCHAR(1),          -- Y/N flag\n",
    "    PULOCATIONID BIGINT,                    -- ID de zona de pickup\n",
    "    DOLOCATIONID BIGINT,                    -- ID de zona de dropoff\n",
    "    PAYMENT_TYPE BIGINT,\n",
    "    FARE_AMOUNT DOUBLE,\n",
    "    EXTRA DOUBLE,\n",
    "    MTA_TAX DOUBLE,\n",
    "    TIP_AMOUNT DOUBLE,\n",
    "    TOLLS_AMOUNT DOUBLE,\n",
    "    IMPROVEMENT_SURCHARGE DOUBLE,\n",
    "    TOTAL_AMOUNT DOUBLE,\n",
    "    CONGESTION_SURCHARGE DOUBLE,\n",
    "    AIRPORT_FEE DOUBLE,\n",
    "    \n",
    "    -- Metadatos de ingesta\n",
    "    RUN_ID INTEGER,                         -- Identificador de ejecución\n",
    "    SERVICE_TYPE VARCHAR(10),               -- 'yellow' o 'green'\n",
    "    SOURCE_YEAR INTEGER,                    -- Año del archivo origen\n",
    "    SOURCE_MONTH INTEGER,                   -- Mes del archivo origen\n",
    "    INGESTED_AT_UTC TIMESTAMP_NTZ,          -- Momento de ingesta\n",
    "    SOURCE_PATH VARCHAR(500),               -- URL del archivo Parquet\n",
    "    BATCH_NUMBER INTEGER                    -- Número de batch (para cargas grandes)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# TABLA RAW PARA GREEN TAXIS:\n",
    "# - Similar a Yellow, pero con campos específicos de Green (LPEP, TRIP_TYPE, EHAIL_FEE)\n",
    "create_green_raw = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS RAW_GREEN_TRIPS (\n",
    "    -- Campos originales del dataset NYC TLC Green\n",
    "    VENDORID BIGINT,\n",
    "    LPEP_PICKUP_DATETIME TIMESTAMP_NTZ,    -- 'L' indica Green taxi\n",
    "    LPEP_DROPOFF_DATETIME TIMESTAMP_NTZ,\n",
    "    PASSENGER_COUNT DOUBLE,\n",
    "    TRIP_DISTANCE DOUBLE,\n",
    "    RATECODEID DOUBLE,\n",
    "    STORE_AND_FWD_FLAG VARCHAR(1),\n",
    "    PULOCATIONID BIGINT,\n",
    "    DOLOCATIONID BIGINT,\n",
    "    PAYMENT_TYPE BIGINT,\n",
    "    FARE_AMOUNT DOUBLE,\n",
    "    EXTRA DOUBLE,\n",
    "    MTA_TAX DOUBLE,\n",
    "    TIP_AMOUNT DOUBLE,\n",
    "    TOLLS_AMOUNT DOUBLE,\n",
    "    IMPROVEMENT_SURCHARGE DOUBLE,\n",
    "    TOTAL_AMOUNT DOUBLE,\n",
    "    TRIP_TYPE BIGINT,                      -- Específico de Green\n",
    "    CONGESTION_SURCHARGE DOUBLE,\n",
    "    EHAIL_FEE DOUBLE,                      -- Específico de Green\n",
    "    \n",
    "    -- Metadatos de ingesta\n",
    "    RUN_ID INTEGER,\n",
    "    SERVICE_TYPE VARCHAR(10),\n",
    "    SOURCE_YEAR INTEGER,\n",
    "    SOURCE_MONTH INTEGER,\n",
    "    INGESTED_AT_UTC TIMESTAMP_NTZ,\n",
    "    SOURCE_PATH VARCHAR(500),\n",
    "    BATCH_NUMBER INTEGER\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# TABLA DE AUDITORÍA:\n",
    "# - Registra TODAS las operaciones de ingesta (exitosas y fallidas).\n",
    "create_audit = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS INGESTA_AUDIT (\n",
    "    AUDIT_ID INTEGER AUTOINCREMENT,          -- ID único autoincremental\n",
    "    RUN_ID INTEGER,                          -- Relaciona con metadatos en RAW\n",
    "    SERVICE_TYPE VARCHAR(10),                -- 'yellow' o 'green'\n",
    "    SOURCE_YEAR INTEGER,\n",
    "    SOURCE_MONTH INTEGER,\n",
    "    SOURCE_PATH VARCHAR(500),                -- URL completa del Parquet\n",
    "    BATCH_NUMBER INTEGER,\n",
    "    ROWS_PROCESSED INTEGER,                  -- Cantidad de filas insertadas\n",
    "    PROCESSING_TIME_SECONDS FLOAT,           -- Tiempo de ejecución\n",
    "    STATUS VARCHAR(20),                      -- 'SUCCESS' o 'FAILED'\n",
    "    ERROR_MESSAGE VARCHAR(1000),             -- Detalle del error (si aplica)\n",
    "    CREATED_AT TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    PRIMARY KEY (AUDIT_ID)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar DDL\n",
    "print(\"Creando tabla RAW_YELLOW_TRIPS...\")\n",
    "cursor.execute(create_yellow_raw)\n",
    "print(\"- Tabla RAW_YELLOW_TRIPS creada/verificada.\")\n",
    "\n",
    "print(\"\\nCreando tabla RAW_GREEN_TRIPS...\")\n",
    "cursor.execute(create_green_raw)\n",
    "print(\"- Tabla RAW_GREEN_TRIPS creada/verificada.\")\n",
    "\n",
    "print(\"\\nCreando tabla INGESTA_AUDIT...\")\n",
    "cursor.execute(create_audit)\n",
    "print(\"- Tabla INGESTA_AUDIT creada/verificada.\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TODAS LAS TABLAS RAW CREADAS EXITOSAMENTE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a22285b4-96fc-49ea-9c96-7890addc5553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FUNCIÓN DE INGESTA DEFINIDA Y LISTA\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Función completa que:\n",
    "# 1. Descarga Parquet desde NYC TLC.\n",
    "# 2. Normaliza tipos y timestamps.\n",
    "# 3. Agrega metadatos de ingesta.\n",
    "# 4. Escribe a Snowflake RAW.\n",
    "# 5. Registra auditoría.\n",
    "# 6. Guarda checkpoint para idempotencia.\n",
    "\n",
    "import time\n",
    "\n",
    "# Esquema esperado por servicio (orden exacto para escritura en Snowflake)\n",
    "EXPECTED_COLUMNS = {\n",
    "    \"yellow\": [\n",
    "        \"VENDORID\", \"TPEP_PICKUP_DATETIME\", \"TPEP_DROPOFF_DATETIME\",\n",
    "        \"PASSENGER_COUNT\", \"TRIP_DISTANCE\", \"RATECODEID\", \"STORE_AND_FWD_FLAG\",\n",
    "        \"PULOCATIONID\", \"DOLOCATIONID\", \"PAYMENT_TYPE\",\n",
    "        \"FARE_AMOUNT\", \"EXTRA\", \"MTA_TAX\", \"TIP_AMOUNT\", \"TOLLS_AMOUNT\",\n",
    "        \"IMPROVEMENT_SURCHARGE\", \"TOTAL_AMOUNT\", \"CONGESTION_SURCHARGE\", \"AIRPORT_FEE\",\n",
    "        # Metadatos\n",
    "        \"RUN_ID\", \"SERVICE_TYPE\", \"SOURCE_YEAR\", \"SOURCE_MONTH\",\n",
    "        \"INGESTED_AT_UTC\", \"SOURCE_PATH\", \"BATCH_NUMBER\",\n",
    "    ],\n",
    "    \"green\": [\n",
    "        \"VENDORID\", \"LPEP_PICKUP_DATETIME\", \"LPEP_DROPOFF_DATETIME\",\n",
    "        \"PASSENGER_COUNT\", \"TRIP_DISTANCE\", \"RATECODEID\", \"STORE_AND_FWD_FLAG\",\n",
    "        \"PULOCATIONID\", \"DOLOCATIONID\", \"PAYMENT_TYPE\",\n",
    "        \"FARE_AMOUNT\", \"EXTRA\", \"MTA_TAX\", \"TIP_AMOUNT\", \"TOLLS_AMOUNT\",\n",
    "        \"IMPROVEMENT_SURCHARGE\", \"TOTAL_AMOUNT\", \"TRIP_TYPE\",\n",
    "        \"CONGESTION_SURCHARGE\", \"EHAIL_FEE\",\n",
    "        # Metadatos\n",
    "        \"RUN_ID\", \"SERVICE_TYPE\", \"SOURCE_YEAR\", \"SOURCE_MONTH\",\n",
    "        \"INGESTED_AT_UTC\", \"SOURCE_PATH\", \"BATCH_NUMBER\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "def _open_sf_conn(schema=None):\n",
    "    \n",
    "    # Abre una conexión directa a Snowflake usando snowflake-connector-python.\n",
    "    # Args:\n",
    "    #    - schema: Si no se provee RAW, usa SNOWFLAKE_SCHEMA_RAW\n",
    "    \n",
    "    return snowflake.connector.connect(\n",
    "        user=os.environ[\"SNOWFLAKE_USER\"],\n",
    "        password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "        database=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "        schema=schema or os.environ[\"SNOWFLAKE_SCHEMA_RAW\"],\n",
    "        role=os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "    )\n",
    "\n",
    "def ingest_parquet_to_raw(service_type, year, month, run_id, batch_size=1000000):\n",
    "    \n",
    "    # Ingesta un archivo Parquet mensual de NYC TLC hacia Snowflake RAW.\n",
    "    \n",
    "    # Proceso completo:\n",
    "    # 1. Descarga el Parquet desde la CDN de NYC TLC.\n",
    "    # 2. Lee el archivo con Spark.\n",
    "    # 3. Normaliza timestamps (TimestampNTZType -> TimestampType).\n",
    "    # 4. Estandariza tipos numéricos.\n",
    "    # 5. Agrega metadatos de lineage.\n",
    "    # 6. Alinea columnas al esquema esperado.\n",
    "    # 7. Escribe a Snowflake en modo APPEND.\n",
    "    # 8. Registra auditoría (exitosa o fallida).\n",
    "    # 9. Guarda checkpoint si fue exitoso.\n",
    "    \n",
    "    # Args:\n",
    "    #     - service_type: 'yellow' o 'green'\n",
    "    #     - year: Año del archivo (2015-2025)\n",
    "    #     - month: Mes del archivo (1-12)\n",
    "    #     - run_id: Identificador único de esta ejecución\n",
    "    #     - batch_size: Tamaño de batch\n",
    "    \n",
    "    # Returns:\n",
    "    #     - bool: True si la ingesta fue exitosa, False si falló\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Construir URL del archivo Parquet\n",
    "    base_url = os.getenv('SOURCE_BASE', 'https://d37ci6vzurychx.cloudfront.net/trip-data')\n",
    "    file_name = f'{service_type}_tripdata_{year}-{month:02d}.parquet'\n",
    "    url = f\"{base_url}/{file_name}\"\n",
    "    table_name = f\"RAW_{service_type.upper()}_TRIPS\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESANDO: {file_name}\")\n",
    "    print(f\"URL: {url}\")\n",
    "    print(f\"Destino: {table_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # PASO 1: DESCARGA DEL PARQUET\n",
    "        print(\"Descargando archivo desde NYC TLC...\")\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0\",\n",
    "            \"Accept\": \"application/octet-stream\"\n",
    "        }\n",
    "        resp = requests.get(url, headers=headers, timeout=120)\n",
    "        resp.raise_for_status()  # Lanza excepción si status != 200\n",
    "        \n",
    "        size_mb = len(resp.content) / 1024 / 1024\n",
    "        print(f\"Descarga completada ({size_mb:.2f} MB)\")\n",
    "        \n",
    "        # PASO 2: LECTURA CON SPARK\n",
    "        print(\"Leyendo Parquet con Spark...\")\n",
    "        temp_path = f\"/tmp/{file_name}\"\n",
    "        with open(temp_path, 'wb') as f:\n",
    "            f.write(resp.content)\n",
    "        \n",
    "        df = spark.read.parquet(temp_path)\n",
    "        print(f\"Parquet leído: {df.count():,} filas\")\n",
    "        \n",
    "        drop_if_exists = [\"cbd_congestion_fee\"]\n",
    "        for c in drop_if_exists:\n",
    "            if c in df.columns:\n",
    "                df = df.drop(c)\n",
    "                print(f\"  - Columna '{c}' eliminada (no necesaria)\")\n",
    "        \n",
    "        # PASO 3: NORMALIZAR NOMBRES A UPPERCASE\n",
    "        # - Importante: Snowflake trata nombres como uppercase por defecto\n",
    "        df = df.toDF(*[c.upper() for c in df.columns])\n",
    "        \n",
    "        # PASO 4: NORMALIZAR TIMESTAMPS\n",
    "        # - TimestampNTZType (sin zona) -> TimestampType (con zona UTC)\n",
    "        # - Esto asegura compatibilidad con Snowflake y consultas posteriores\n",
    "        ntz_cols = []\n",
    "        for field in df.schema.fields:\n",
    "            # Verificar si es TimestampNTZType\n",
    "            if isinstance(field.dataType, getattr(T, \"TimestampNTZType\", type(None))):\n",
    "                ntz_cols.append(field.name)\n",
    "        \n",
    "        for c in ntz_cols:\n",
    "            df = df.withColumn(c, F.col(c).cast(T.TimestampType()))\n",
    "            print(f\"  - Columna '{c}' convertida: TimestampNTZType -> TimestampType\")\n",
    "        \n",
    "        # PASO 5: CASTING NUMÉRICO CONSISTENTE\n",
    "        # - Asegurar que los tipos coincidan con las tablas RAW en Snowflake\n",
    "        \n",
    "        # Columnas que deben ser BIGINT (IDs)\n",
    "        long_cols = [\"VENDORID\", \"PULOCATIONID\", \"DOLOCATIONID\", \"PAYMENT_TYPE\", \"TRIP_TYPE\"]\n",
    "        for c in long_cols:\n",
    "            if c in df.columns:\n",
    "                df = df.withColumn(c, F.col(c).cast(T.LongType()))\n",
    "        \n",
    "        # Columnas que deben ser DOUBLE (métricas y montos)\n",
    "        double_cols = [\n",
    "            \"PASSENGER_COUNT\", \"TRIP_DISTANCE\", \"RATECODEID\",\n",
    "            \"FARE_AMOUNT\", \"EXTRA\", \"MTA_TAX\", \"TIP_AMOUNT\", \"TOLLS_AMOUNT\",\n",
    "            \"IMPROVEMENT_SURCHARGE\", \"TOTAL_AMOUNT\", \"CONGESTION_SURCHARGE\",\n",
    "            \"AIRPORT_FEE\", \"EHAIL_FEE\"\n",
    "        ]\n",
    "        for c in double_cols:\n",
    "            if c in df.columns:\n",
    "                df = df.withColumn(c, F.col(c).cast(T.DoubleType()))\n",
    "        \n",
    "        print(\"- Tipos de datos normalizados.\")\n",
    "        \n",
    "        # PASO 6: AGREGAR METADATOS DE LINEAGE\n",
    "        # - Crítico para rastreabilidad y auditoría\n",
    "        df = (df\n",
    "              .withColumn(\"RUN_ID\", F.lit(run_id))\n",
    "              .withColumn(\"SERVICE_TYPE\", F.lit(service_type))\n",
    "              .withColumn(\"SOURCE_YEAR\", F.lit(year))\n",
    "              .withColumn(\"SOURCE_MONTH\", F.lit(month))\n",
    "              .withColumn(\"INGESTED_AT_UTC\", F.current_timestamp().cast(T.TimestampType()))\n",
    "              .withColumn(\"SOURCE_PATH\", F.lit(url))\n",
    "              .withColumn(\"BATCH_NUMBER\", F.lit(1))  # Reservado para cargas por batch\n",
    "        )\n",
    "        \n",
    "        total_rows = df.count()\n",
    "        print(f\"- Metadatos agregados: {total_rows:,} filas listas para carga.\")\n",
    "        \n",
    "        # PASO 7: ALINEAR COLUMNAS AL ESQUEMA ESPERADO\n",
    "        # - Asegurar que todas las columnas esperadas existan (agregar NULLs si faltan)\n",
    "        expected = EXPECTED_COLUMNS[service_type]\n",
    "        for c in expected:\n",
    "            if c not in df.columns:\n",
    "                df = df.withColumn(c, F.lit(None))\n",
    "                print(f\"  - Columna '{c}' agregada con NULL (no existe en origen).\")\n",
    "        \n",
    "        # Reordenar columnas en el orden esperado\n",
    "        df = df.select(*expected)\n",
    "        \n",
    "        # PASO 8: ESCRIBIR A SNOWFLAKE\n",
    "        print(f\"Escribiendo a Snowflake ({table_name})...\")\n",
    "        (df.write\n",
    "           .format(\"snowflake\")\n",
    "           .options(**snowflake_options)\n",
    "           .option(\"dbtable\", table_name)\n",
    "           .option(\"sessionParams\", \"TIMEZONE=UTC\")  # Asegurar timezone UTC\n",
    "           .option(\"onError\", \"CONTINUE\")             # Continuar si hay errores en filas\n",
    "           .mode(\"append\")                            # APPEND: no sobrescribe datos existentes\n",
    "           .save()\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"- Carga completada en {elapsed:.2f} segundos\")\n",
    "        \n",
    "        # PASO 9: REGISTRAR AUDITORÍA EXITOSA\n",
    "        conn = _open_sf_conn(schema=os.environ[\"SNOWFLAKE_SCHEMA_RAW\"])\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"\"\"\n",
    "            INSERT INTO INGESTA_AUDIT \n",
    "            (RUN_ID, SERVICE_TYPE, SOURCE_YEAR, SOURCE_MONTH, SOURCE_PATH, \n",
    "             BATCH_NUMBER, ROWS_PROCESSED, PROCESSING_TIME_SECONDS, STATUS)\n",
    "            VALUES ({run_id}, '{service_type}', {year}, {month}, '{url}', \n",
    "                    1, {total_rows}, {elapsed}, 'SUCCESS')\n",
    "        \"\"\")\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        print(\"- Auditoría registrada: SUCCESS.\")\n",
    "        \n",
    "        # PASO 10: GUARDAR CHECKPOINT Y LIMPIAR\n",
    "        save_checkpoint(service_type, year, month)\n",
    "        \n",
    "        # Limpiar archivo temporal\n",
    "        try:\n",
    "            os.remove(temp_path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        # Error HTTP (ej: 403 Forbidden, 404 Not Found)\n",
    "        status = getattr(e.response, \"status_code\", None)\n",
    "        msg = f\"HTTP {status}\" if status else str(e)\n",
    "        print(f\"Error HTTP: {msg}\")\n",
    "        \n",
    "        # Registrar auditoría de fallo\n",
    "        try:\n",
    "            elapsed = time.time() - start_time\n",
    "            conn = _open_sf_conn(schema=os.environ[\"SNOWFLAKE_SCHEMA_RAW\"])\n",
    "            cur = conn.cursor()\n",
    "            err = msg.replace(\"'\", \"\")[:1000]  # Sanitizar comillas\n",
    "            cur.execute(f\"\"\"\n",
    "                INSERT INTO INGESTA_AUDIT \n",
    "                (RUN_ID, SERVICE_TYPE, SOURCE_YEAR, SOURCE_MONTH, SOURCE_PATH, \n",
    "                 PROCESSING_TIME_SECONDS, STATUS, ERROR_MESSAGE)\n",
    "                VALUES ({run_id}, '{service_type}', {year}, {month}, '{url}', \n",
    "                        {elapsed}, 'FAILED', '{err}')\n",
    "            \"\"\")\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Cualquier otro error (parsing, Snowflake, etc.)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n",
    "        # Registrar auditoría de fallo\n",
    "        try:\n",
    "            conn = _open_sf_conn(schema=os.environ[\"SNOWFLAKE_SCHEMA_RAW\"])\n",
    "            cur = conn.cursor()\n",
    "            err = str(e).replace(\"'\", \"\")[:1000]\n",
    "            cur.execute(f\"\"\"\n",
    "                INSERT INTO INGESTA_AUDIT \n",
    "                (RUN_ID, SERVICE_TYPE, SOURCE_YEAR, SOURCE_MONTH, SOURCE_PATH, \n",
    "                 PROCESSING_TIME_SECONDS, STATUS, ERROR_MESSAGE)\n",
    "                VALUES ({run_id}, '{service_type}', {year}, {month}, '{url}', \n",
    "                        {elapsed}, 'FAILED', '{err}')\n",
    "            \"\"\")\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Limpiar archivo temporal si existe\n",
    "        try:\n",
    "            os.remove(temp_path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return False\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FUNCIÓN DE INGESTA DEFINIDA Y LISTA\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "394d1dfb-a792-4c82-bf40-ae45d6acd355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INICIANDO INGESTA COMPLETA A RAW\n",
      "================================================================================\n",
      "Periodo: 2015-2025\n",
      "Servicios: yellow, green\n",
      "Run ID: 1\n",
      "Checkpoint file: /home/jovyan/work/checkpoint_ingesta.json\n",
      "================================================================================\n",
      "\n",
      "\n",
      "################################################################################\n",
      "SERVICIO: YELLOW\n",
      "################################################################################\n",
      "SALTANDO yellow 2015-01 (ya procesado).\n",
      "SALTANDO yellow 2015-02 (ya procesado).\n",
      "SALTANDO yellow 2015-03 (ya procesado).\n",
      "SALTANDO yellow 2015-04 (ya procesado).\n",
      "SALTANDO yellow 2015-05 (ya procesado).\n",
      "SALTANDO yellow 2015-06 (ya procesado).\n",
      "SALTANDO yellow 2015-07 (ya procesado).\n",
      "SALTANDO yellow 2015-08 (ya procesado).\n",
      "SALTANDO yellow 2015-09 (ya procesado).\n",
      "SALTANDO yellow 2015-10 (ya procesado).\n",
      "SALTANDO yellow 2015-11 (ya procesado).\n",
      "SALTANDO yellow 2015-12 (ya procesado).\n",
      "SALTANDO yellow 2016-01 (ya procesado).\n",
      "SALTANDO yellow 2016-02 (ya procesado).\n",
      "SALTANDO yellow 2016-03 (ya procesado).\n",
      "SALTANDO yellow 2016-04 (ya procesado).\n",
      "SALTANDO yellow 2016-05 (ya procesado).\n",
      "SALTANDO yellow 2016-06 (ya procesado).\n",
      "SALTANDO yellow 2016-07 (ya procesado).\n",
      "SALTANDO yellow 2016-08 (ya procesado).\n",
      "SALTANDO yellow 2016-09 (ya procesado).\n",
      "SALTANDO yellow 2016-10 (ya procesado).\n",
      "SALTANDO yellow 2016-11 (ya procesado).\n",
      "SALTANDO yellow 2016-12 (ya procesado).\n",
      "SALTANDO yellow 2017-01 (ya procesado).\n",
      "SALTANDO yellow 2017-02 (ya procesado).\n",
      "SALTANDO yellow 2017-03 (ya procesado).\n",
      "SALTANDO yellow 2017-04 (ya procesado).\n",
      "SALTANDO yellow 2017-05 (ya procesado).\n",
      "SALTANDO yellow 2017-06 (ya procesado).\n",
      "SALTANDO yellow 2017-07 (ya procesado).\n",
      "SALTANDO yellow 2017-08 (ya procesado).\n",
      "SALTANDO yellow 2017-09 (ya procesado).\n",
      "SALTANDO yellow 2017-10 (ya procesado).\n",
      "SALTANDO yellow 2017-11 (ya procesado).\n",
      "SALTANDO yellow 2017-12 (ya procesado).\n",
      "SALTANDO yellow 2018-01 (ya procesado).\n",
      "SALTANDO yellow 2018-02 (ya procesado).\n",
      "SALTANDO yellow 2018-03 (ya procesado).\n",
      "SALTANDO yellow 2018-04 (ya procesado).\n",
      "SALTANDO yellow 2018-05 (ya procesado).\n",
      "SALTANDO yellow 2018-06 (ya procesado).\n",
      "SALTANDO yellow 2018-07 (ya procesado).\n",
      "SALTANDO yellow 2018-08 (ya procesado).\n",
      "SALTANDO yellow 2018-09 (ya procesado).\n",
      "SALTANDO yellow 2018-10 (ya procesado).\n",
      "SALTANDO yellow 2018-11 (ya procesado).\n",
      "SALTANDO yellow 2018-12 (ya procesado).\n",
      "SALTANDO yellow 2019-01 (ya procesado).\n",
      "SALTANDO yellow 2019-02 (ya procesado).\n",
      "SALTANDO yellow 2019-03 (ya procesado).\n",
      "SALTANDO yellow 2019-04 (ya procesado).\n",
      "SALTANDO yellow 2019-05 (ya procesado).\n",
      "SALTANDO yellow 2019-06 (ya procesado).\n",
      "SALTANDO yellow 2019-07 (ya procesado).\n",
      "SALTANDO yellow 2019-08 (ya procesado).\n",
      "SALTANDO yellow 2019-09 (ya procesado).\n",
      "SALTANDO yellow 2019-10 (ya procesado).\n",
      "SALTANDO yellow 2019-11 (ya procesado).\n",
      "SALTANDO yellow 2019-12 (ya procesado).\n",
      "SALTANDO yellow 2020-01 (ya procesado).\n",
      "SALTANDO yellow 2020-02 (ya procesado).\n",
      "SALTANDO yellow 2020-03 (ya procesado).\n",
      "SALTANDO yellow 2020-04 (ya procesado).\n",
      "SALTANDO yellow 2020-05 (ya procesado).\n",
      "SALTANDO yellow 2020-06 (ya procesado).\n",
      "SALTANDO yellow 2020-07 (ya procesado).\n",
      "SALTANDO yellow 2020-08 (ya procesado).\n",
      "SALTANDO yellow 2020-09 (ya procesado).\n",
      "SALTANDO yellow 2020-10 (ya procesado).\n",
      "SALTANDO yellow 2020-11 (ya procesado).\n",
      "SALTANDO yellow 2020-12 (ya procesado).\n",
      "SALTANDO yellow 2021-01 (ya procesado).\n",
      "SALTANDO yellow 2021-02 (ya procesado).\n",
      "SALTANDO yellow 2021-03 (ya procesado).\n",
      "SALTANDO yellow 2021-04 (ya procesado).\n",
      "SALTANDO yellow 2021-05 (ya procesado).\n",
      "SALTANDO yellow 2021-06 (ya procesado).\n",
      "SALTANDO yellow 2021-07 (ya procesado).\n",
      "SALTANDO yellow 2021-08 (ya procesado).\n",
      "SALTANDO yellow 2021-09 (ya procesado).\n",
      "SALTANDO yellow 2021-10 (ya procesado).\n",
      "SALTANDO yellow 2021-11 (ya procesado).\n",
      "SALTANDO yellow 2021-12 (ya procesado).\n",
      "SALTANDO yellow 2022-01 (ya procesado).\n",
      "SALTANDO yellow 2022-02 (ya procesado).\n",
      "SALTANDO yellow 2022-03 (ya procesado).\n",
      "SALTANDO yellow 2022-04 (ya procesado).\n",
      "SALTANDO yellow 2022-05 (ya procesado).\n",
      "SALTANDO yellow 2022-06 (ya procesado).\n",
      "SALTANDO yellow 2022-07 (ya procesado).\n",
      "SALTANDO yellow 2022-08 (ya procesado).\n",
      "SALTANDO yellow 2022-09 (ya procesado).\n",
      "SALTANDO yellow 2022-10 (ya procesado).\n",
      "SALTANDO yellow 2022-11 (ya procesado).\n",
      "SALTANDO yellow 2022-12 (ya procesado).\n",
      "SALTANDO yellow 2023-01 (ya procesado).\n",
      "SALTANDO yellow 2023-02 (ya procesado).\n",
      "SALTANDO yellow 2023-03 (ya procesado).\n",
      "SALTANDO yellow 2023-04 (ya procesado).\n",
      "SALTANDO yellow 2023-05 (ya procesado).\n",
      "SALTANDO yellow 2023-06 (ya procesado).\n",
      "SALTANDO yellow 2023-07 (ya procesado).\n",
      "SALTANDO yellow 2023-08 (ya procesado).\n",
      "SALTANDO yellow 2023-09 (ya procesado).\n",
      "SALTANDO yellow 2023-10 (ya procesado).\n",
      "SALTANDO yellow 2023-11 (ya procesado).\n",
      "SALTANDO yellow 2023-12 (ya procesado).\n",
      "SALTANDO yellow 2024-01 (ya procesado).\n",
      "SALTANDO yellow 2024-02 (ya procesado).\n",
      "SALTANDO yellow 2024-03 (ya procesado).\n",
      "SALTANDO yellow 2024-04 (ya procesado).\n",
      "SALTANDO yellow 2024-05 (ya procesado).\n",
      "SALTANDO yellow 2024-06 (ya procesado).\n",
      "SALTANDO yellow 2024-07 (ya procesado).\n",
      "SALTANDO yellow 2024-08 (ya procesado).\n",
      "SALTANDO yellow 2024-09 (ya procesado).\n",
      "SALTANDO yellow 2024-10 (ya procesado).\n",
      "SALTANDO yellow 2024-11 (ya procesado).\n",
      "SALTANDO yellow 2024-12 (ya procesado).\n",
      "SALTANDO yellow 2025-01 (ya procesado).\n",
      "SALTANDO yellow 2025-02 (ya procesado).\n",
      "SALTANDO yellow 2025-03 (ya procesado).\n",
      "SALTANDO yellow 2025-04 (ya procesado).\n",
      "SALTANDO yellow 2025-05 (ya procesado).\n",
      "SALTANDO yellow 2025-06 (ya procesado).\n",
      "SALTANDO yellow 2025-07 (ya procesado).\n",
      "SALTANDO yellow 2025-08 (ya procesado).\n",
      "\n",
      "################################################################################\n",
      "SERVICIO: GREEN\n",
      "################################################################################\n",
      "SALTANDO green 2015-01 (ya procesado).\n",
      "SALTANDO green 2015-02 (ya procesado).\n",
      "SALTANDO green 2015-03 (ya procesado).\n",
      "SALTANDO green 2015-04 (ya procesado).\n",
      "SALTANDO green 2015-05 (ya procesado).\n",
      "SALTANDO green 2015-06 (ya procesado).\n",
      "SALTANDO green 2015-07 (ya procesado).\n",
      "SALTANDO green 2015-08 (ya procesado).\n",
      "SALTANDO green 2015-09 (ya procesado).\n",
      "SALTANDO green 2015-10 (ya procesado).\n",
      "SALTANDO green 2015-11 (ya procesado).\n",
      "SALTANDO green 2015-12 (ya procesado).\n",
      "SALTANDO green 2016-01 (ya procesado).\n",
      "SALTANDO green 2016-02 (ya procesado).\n",
      "SALTANDO green 2016-03 (ya procesado).\n",
      "SALTANDO green 2016-04 (ya procesado).\n",
      "SALTANDO green 2016-05 (ya procesado).\n",
      "SALTANDO green 2016-06 (ya procesado).\n",
      "SALTANDO green 2016-07 (ya procesado).\n",
      "SALTANDO green 2016-08 (ya procesado).\n",
      "SALTANDO green 2016-09 (ya procesado).\n",
      "SALTANDO green 2016-10 (ya procesado).\n",
      "SALTANDO green 2016-11 (ya procesado).\n",
      "SALTANDO green 2016-12 (ya procesado).\n",
      "SALTANDO green 2017-01 (ya procesado).\n",
      "SALTANDO green 2017-02 (ya procesado).\n",
      "SALTANDO green 2017-03 (ya procesado).\n",
      "SALTANDO green 2017-04 (ya procesado).\n",
      "SALTANDO green 2017-05 (ya procesado).\n",
      "SALTANDO green 2017-06 (ya procesado).\n",
      "SALTANDO green 2017-07 (ya procesado).\n",
      "SALTANDO green 2017-08 (ya procesado).\n",
      "SALTANDO green 2017-09 (ya procesado).\n",
      "SALTANDO green 2017-10 (ya procesado).\n",
      "SALTANDO green 2017-11 (ya procesado).\n",
      "SALTANDO green 2017-12 (ya procesado).\n",
      "SALTANDO green 2018-01 (ya procesado).\n",
      "SALTANDO green 2018-02 (ya procesado).\n",
      "SALTANDO green 2018-03 (ya procesado).\n",
      "SALTANDO green 2018-04 (ya procesado).\n",
      "SALTANDO green 2018-05 (ya procesado).\n",
      "SALTANDO green 2018-06 (ya procesado).\n",
      "SALTANDO green 2018-07 (ya procesado).\n",
      "SALTANDO green 2018-08 (ya procesado).\n",
      "SALTANDO green 2018-09 (ya procesado).\n",
      "SALTANDO green 2018-10 (ya procesado).\n",
      "SALTANDO green 2018-11 (ya procesado).\n",
      "SALTANDO green 2018-12 (ya procesado).\n",
      "SALTANDO green 2019-01 (ya procesado).\n",
      "SALTANDO green 2019-02 (ya procesado).\n",
      "SALTANDO green 2019-03 (ya procesado).\n",
      "SALTANDO green 2019-04 (ya procesado).\n",
      "SALTANDO green 2019-05 (ya procesado).\n",
      "SALTANDO green 2019-06 (ya procesado).\n",
      "SALTANDO green 2019-07 (ya procesado).\n",
      "SALTANDO green 2019-08 (ya procesado).\n",
      "SALTANDO green 2019-09 (ya procesado).\n",
      "SALTANDO green 2019-10 (ya procesado).\n",
      "SALTANDO green 2019-11 (ya procesado).\n",
      "SALTANDO green 2019-12 (ya procesado).\n",
      "SALTANDO green 2020-01 (ya procesado).\n",
      "SALTANDO green 2020-02 (ya procesado).\n",
      "SALTANDO green 2020-03 (ya procesado).\n",
      "SALTANDO green 2020-04 (ya procesado).\n",
      "SALTANDO green 2020-05 (ya procesado).\n",
      "SALTANDO green 2020-06 (ya procesado).\n",
      "SALTANDO green 2020-07 (ya procesado).\n",
      "SALTANDO green 2020-08 (ya procesado).\n",
      "SALTANDO green 2020-09 (ya procesado).\n",
      "SALTANDO green 2020-10 (ya procesado).\n",
      "SALTANDO green 2020-11 (ya procesado).\n",
      "SALTANDO green 2020-12 (ya procesado).\n",
      "SALTANDO green 2021-01 (ya procesado).\n",
      "SALTANDO green 2021-02 (ya procesado).\n",
      "SALTANDO green 2021-03 (ya procesado).\n",
      "SALTANDO green 2021-04 (ya procesado).\n",
      "SALTANDO green 2021-05 (ya procesado).\n",
      "SALTANDO green 2021-06 (ya procesado).\n",
      "SALTANDO green 2021-07 (ya procesado).\n",
      "SALTANDO green 2021-08 (ya procesado).\n",
      "SALTANDO green 2021-09 (ya procesado).\n",
      "SALTANDO green 2021-10 (ya procesado).\n",
      "SALTANDO green 2021-11 (ya procesado).\n",
      "SALTANDO green 2021-12 (ya procesado).\n",
      "SALTANDO green 2022-01 (ya procesado).\n",
      "SALTANDO green 2022-02 (ya procesado).\n",
      "SALTANDO green 2022-03 (ya procesado).\n",
      "SALTANDO green 2022-04 (ya procesado).\n",
      "SALTANDO green 2022-05 (ya procesado).\n",
      "SALTANDO green 2022-06 (ya procesado).\n",
      "SALTANDO green 2022-07 (ya procesado).\n",
      "SALTANDO green 2022-08 (ya procesado).\n",
      "SALTANDO green 2022-09 (ya procesado).\n",
      "SALTANDO green 2022-10 (ya procesado).\n",
      "SALTANDO green 2022-11 (ya procesado).\n",
      "SALTANDO green 2022-12 (ya procesado).\n",
      "SALTANDO green 2023-01 (ya procesado).\n",
      "SALTANDO green 2023-02 (ya procesado).\n",
      "SALTANDO green 2023-03 (ya procesado).\n",
      "SALTANDO green 2023-04 (ya procesado).\n",
      "SALTANDO green 2023-05 (ya procesado).\n",
      "SALTANDO green 2023-06 (ya procesado).\n",
      "SALTANDO green 2023-07 (ya procesado).\n",
      "SALTANDO green 2023-08 (ya procesado).\n",
      "SALTANDO green 2023-09 (ya procesado).\n",
      "SALTANDO green 2023-10 (ya procesado).\n",
      "SALTANDO green 2023-11 (ya procesado).\n",
      "SALTANDO green 2023-12 (ya procesado).\n",
      "SALTANDO green 2024-01 (ya procesado).\n",
      "SALTANDO green 2024-02 (ya procesado).\n",
      "SALTANDO green 2024-03 (ya procesado).\n",
      "SALTANDO green 2024-04 (ya procesado).\n",
      "SALTANDO green 2024-05 (ya procesado).\n",
      "SALTANDO green 2024-06 (ya procesado).\n",
      "SALTANDO green 2024-07 (ya procesado).\n",
      "SALTANDO green 2024-08 (ya procesado).\n",
      "SALTANDO green 2024-09 (ya procesado).\n",
      "SALTANDO green 2024-10 (ya procesado).\n",
      "SALTANDO green 2024-11 (ya procesado).\n",
      "SALTANDO green 2024-12 (ya procesado).\n",
      "SALTANDO green 2025-01 (ya procesado).\n",
      "SALTANDO green 2025-02 (ya procesado).\n",
      "SALTANDO green 2025-03 (ya procesado).\n",
      "SALTANDO green 2025-04 (ya procesado).\n",
      "SALTANDO green 2025-05 (ya procesado).\n",
      "SALTANDO green 2025-06 (ya procesado).\n",
      "SALTANDO green 2025-07 (ya procesado).\n",
      "SALTANDO green 2025-08 (ya procesado).\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DE INGESTA\n",
      "================================================================================\n",
      "Total de archivos evaluados: 256\n",
      "Exitosos (nuevos): 0\n",
      "Fallidos: 0\n",
      "Saltados (ya procesados): 256\n",
      "================================================================================\n",
      "Todos los archivos disponibles fueron procesados exitosamente.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Loop principal que:\n",
    "# 1. Itera sobre todos los años/meses/servicios configurados.\n",
    "# 2. Verifica checkpoints (idempotencia).\n",
    "# 3. Llama a la función de ingesta.\n",
    "# 4. Genera resumen final.\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# PARÁMETROS DE INGESTA (desde variables de ambiente):\n",
    "START_YEAR = int(os.getenv('START_YEAR', 2015))\n",
    "END_YEAR = int(os.getenv('END_YEAR', 2025))\n",
    "SERVICES = [s.strip() for s in os.getenv('SERVICES', 'yellow,green').split(',')]\n",
    "RUN_ID = int(os.getenv('RUN_ID', 1))\n",
    "\n",
    "# LÍMITE MÁXIMO: Agosto 2025 (según disponibilidad de datos NYC TLC)\n",
    "MAX_YEAR = 2025\n",
    "MAX_MONTH = 8\n",
    "\n",
    "# Cargar checkpoints existentes\n",
    "checkpoint = load_checkpoint()\n",
    "\n",
    "# Contadores para resumen\n",
    "total_files = 0\n",
    "success_count = 0\n",
    "failed_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "# Obtener fecha/hora actual para validación\n",
    "now = datetime.utcnow()\n",
    "current_year = now.year\n",
    "current_month = now.month\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INICIANDO INGESTA COMPLETA A RAW\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Periodo: {START_YEAR}-{END_YEAR}\")\n",
    "print(f\"Servicios: {', '.join(SERVICES)}\")\n",
    "print(f\"Run ID: {RUN_ID}\")\n",
    "print(f\"Checkpoint file: {CHECKPOINT_FILE}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# LOOP PRINCIPAL DE INGESTA:\n",
    "for service in SERVICES:\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"SERVICIO: {service.upper()}\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        for month in range(1, 13):\n",
    "            # VALIDACIÓN 1: No procesar meses futuros (según fecha actual UTC)\n",
    "            if (year > current_year) or (year == current_year and month > current_month):\n",
    "                break\n",
    "            \n",
    "            # VALIDACIÓN 2: No procesar más allá de agosto 2025 (límite de datos disponibles)\n",
    "            if (year > MAX_YEAR) or (year == MAX_YEAR and month > MAX_MONTH):\n",
    "                break\n",
    "            \n",
    "            total_files += 1\n",
    "            \n",
    "            # VALIDACIÓN 3: Verificar checkpoint (idempotencia)\n",
    "            if is_processed(checkpoint, service, year, month):\n",
    "                print(f\"SALTANDO {service} {year}-{month:02d} (ya procesado).\")\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Ejecutar ingesta para este mes\n",
    "            ok = ingest_parquet_to_raw(service, year, month, RUN_ID)\n",
    "            \n",
    "            if ok:\n",
    "                success_count += 1\n",
    "            else:\n",
    "                failed_count += 1\n",
    "            \n",
    "            # Pausa entre peticiones para no saturar la CDN\n",
    "            import time as _time\n",
    "            _time.sleep(2)\n",
    "\n",
    "# RESUMEN FINAL:\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DE INGESTA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total de archivos evaluados: {total_files}\")\n",
    "print(f\"Exitosos (nuevos): {success_count}\")\n",
    "print(f\"Fallidos: {failed_count}\")\n",
    "print(f\"Saltados (ya procesados): {skipped_count}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if failed_count > 0:\n",
    "    print(\"ATENCIÓN: Hubo archivos fallidos. Revisa la tabla INGESTA_AUDIT para detalles.\")\n",
    "else:\n",
    "    print(\"Todos los archivos disponibles fueron procesados exitosamente.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb8bf4b2-96bf-4290-baea-aca0a24b7aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VERIFICACIÓN DE DATOS EN SNOWFLAKE RAW\n",
      "================================================================================\n",
      "\n",
      "CONTEOS TOTALES\n",
      "--------------------------------------------------------------------------------\n",
      "RAW_YELLOW_TRIPS: 821,925,430 filas\n",
      "RAW_GREEN_TRIPS:  68,045,597 filas\n",
      "TOTAL GENERAL:    889,971,027 filas\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DISTRIBUCIÓN YELLOW (año-mes)\n",
      "--------------------------------------------------------------------------------\n",
      "  2015-01: 12,741,035 viajes\n",
      "  2015-02: 12,442,394 viajes\n",
      "  2015-03: 26,685,902 viajes\n",
      "  2015-04: 26,127,516 viajes\n",
      "  2015-05: 13,157,677 viajes\n",
      "  2015-06: 12,324,936 viajes\n",
      "  2015-07: 11,559,666 viajes\n",
      "  2015-08: 11,123,123 viajes\n",
      "  2015-09: 11,218,122 viajes\n",
      "  2015-10: 12,307,333 viajes\n",
      "  2015-11: 11,305,240 viajes\n",
      "  2015-12: 11,452,996 viajes\n",
      "  2016-01: 10,905,067 viajes\n",
      "  2016-02: 11,375,412 viajes\n",
      "  2016-03: 12,203,824 viajes\n",
      "  2016-04: 11,927,996 viajes\n",
      "  2016-05: 11,832,049 viajes\n",
      "  2016-06: 22,263,290 viajes\n",
      "  2016-07: 10,294,080 viajes\n",
      "  2016-08: 9,942,263 viajes\n",
      "  2016-09: 10,116,018 viajes\n",
      "  2016-10: 10,854,626 viajes\n",
      "  2016-11: 10,102,128 viajes\n",
      "  2016-12: 10,446,697 viajes\n",
      "  2017-01: 9,710,820 viajes\n",
      "  2017-02: 9,169,775 viajes\n",
      "  2017-03: 10,295,441 viajes\n",
      "  2017-04: 10,047,135 viajes\n",
      "  2017-05: 10,102,127 viajes\n",
      "  2017-06: 9,656,993 viajes\n",
      "  2017-07: 8,588,486 viajes\n",
      "  2017-08: 8,422,153 viajes\n",
      "  2017-09: 8,945,421 viajes\n",
      "  2017-10: 9,768,672 viajes\n",
      "  2017-11: 9,284,803 viajes\n",
      "  2017-12: 9,508,501 viajes\n",
      "  2018-01: 8,760,687 viajes\n",
      "  2018-02: 8,492,819 viajes\n",
      "  2018-03: 9,431,289 viajes\n",
      "  2018-04: 9,306,216 viajes\n",
      "  2018-05: 9,224,788 viajes\n",
      "  2018-06: 8,714,667 viajes\n",
      "  2018-07: 7,851,143 viajes\n",
      "  2018-08: 7,855,040 viajes\n",
      "  2018-09: 8,049,094 viajes\n",
      "  2018-10: 8,834,520 viajes\n",
      "  2018-11: 8,155,449 viajes\n",
      "  2018-12: 8,195,675 viajes\n",
      "  2019-01: 7,696,617 viajes\n",
      "  2019-02: 7,049,370 viajes\n",
      "  2019-03: 7,866,620 viajes\n",
      "  2019-04: 7,475,949 viajes\n",
      "  2019-05: 7,598,445 viajes\n",
      "  2019-06: 6,971,560 viajes\n",
      "  2019-07: 6,310,419 viajes\n",
      "  2019-08: 6,073,357 viajes\n",
      "  2019-09: 6,567,788 viajes\n",
      "  2019-10: 7,213,891 viajes\n",
      "  2019-11: 6,878,111 viajes\n",
      "  2019-12: 6,896,317 viajes\n",
      "  2020-01: 6,405,008 viajes\n",
      "  2020-02: 6,299,367 viajes\n",
      "  2020-03: 3,007,687 viajes\n",
      "  2020-04: 238,073 viajes\n",
      "  2020-05: 348,415 viajes\n",
      "  2020-06: 549,797 viajes\n",
      "  2020-07: 800,412 viajes\n",
      "  2020-08: 1,007,286 viajes\n",
      "  2020-09: 1,341,017 viajes\n",
      "  2020-10: 1,681,132 viajes\n",
      "  2020-11: 1,509,000 viajes\n",
      "  2020-12: 1,461,898 viajes\n",
      "  2021-01: 1,369,769 viajes\n",
      "  2021-02: 1,371,709 viajes\n",
      "  2021-03: 1,925,152 viajes\n",
      "  2021-04: 2,171,187 viajes\n",
      "  2021-05: 2,507,109 viajes\n",
      "  2021-06: 2,834,264 viajes\n",
      "  2021-07: 2,821,746 viajes\n",
      "  2021-08: 2,788,757 viajes\n",
      "  2021-09: 2,963,793 viajes\n",
      "  2021-10: 3,463,504 viajes\n",
      "  2021-11: 3,472,949 viajes\n",
      "  2021-12: 3,214,369 viajes\n",
      "  2022-01: 2,463,931 viajes\n",
      "  2022-02: 2,979,431 viajes\n",
      "  2022-03: 3,627,882 viajes\n",
      "  2022-04: 3,599,920 viajes\n",
      "  2022-05: 3,588,295 viajes\n",
      "  2022-06: 3,558,124 viajes\n",
      "  2022-07: 3,174,394 viajes\n",
      "  2022-08: 3,152,677 viajes\n",
      "  2022-09: 3,183,767 viajes\n",
      "  2022-10: 3,675,411 viajes\n",
      "  2022-11: 3,252,717 viajes\n",
      "  2022-12: 3,399,549 viajes\n",
      "  2023-01: 3,066,766 viajes\n",
      "  2023-02: 2,913,955 viajes\n",
      "  2023-03: 3,403,766 viajes\n",
      "  2023-04: 3,288,250 viajes\n",
      "  2023-05: 3,513,649 viajes\n",
      "  2023-06: 3,307,234 viajes\n",
      "  2023-07: 2,907,108 viajes\n",
      "  2023-08: 2,824,209 viajes\n",
      "  2023-09: 2,846,722 viajes\n",
      "  2023-10: 3,522,285 viajes\n",
      "  2023-11: 3,339,715 viajes\n",
      "  2023-12: 3,376,567 viajes\n",
      "  2024-01: 2,964,624 viajes\n",
      "  2024-02: 3,007,526 viajes\n",
      "  2024-03: 3,582,628 viajes\n",
      "  2024-04: 3,514,289 viajes\n",
      "  2024-05: 3,723,833 viajes\n",
      "  2024-06: 3,539,193 viajes\n",
      "  2024-07: 3,076,903 viajes\n",
      "  2024-08: 2,979,183 viajes\n",
      "  2024-09: 3,633,030 viajes\n",
      "  2024-10: 3,833,771 viajes\n",
      "  2024-11: 3,646,369 viajes\n",
      "  2024-12: 3,668,371 viajes\n",
      "  2025-01: 3,475,226 viajes\n",
      "  2025-02: 3,577,543 viajes\n",
      "  2025-03: 4,145,257 viajes\n",
      "  2025-04: 3,970,553 viajes\n",
      "  2025-05: 4,591,845 viajes\n",
      "  2025-06: 4,322,960 viajes\n",
      "  2025-07: 3,898,963 viajes\n",
      "  2025-08: 3,574,091 viajes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DISTRIBUCIÓN GREEN (año-mes)\n",
      "--------------------------------------------------------------------------------\n",
      "  2015-01: 1,508,493 viajes\n",
      "  2015-02: 1,574,830 viajes\n",
      "  2015-03: 1,722,574 viajes\n",
      "  2015-04: 1,664,394 viajes\n",
      "  2015-05: 1,786,848 viajes\n",
      "  2015-06: 1,638,868 viajes\n",
      "  2015-07: 1,541,671 viajes\n",
      "  2015-08: 1,532,343 viajes\n",
      "  2015-09: 1,494,927 viajes\n",
      "  2015-10: 1,630,536 viajes\n",
      "  2015-11: 1,529,984 viajes\n",
      "  2015-12: 1,608,297 viajes\n",
      "  2016-01: 1,445,292 viajes\n",
      "  2016-02: 1,510,722 viajes\n",
      "  2016-03: 1,576,393 viajes\n",
      "  2016-04: 1,543,926 viajes\n",
      "  2016-05: 1,536,979 viajes\n",
      "  2016-06: 1,404,727 viajes\n",
      "  2016-07: 1,332,510 viajes\n",
      "  2016-08: 1,247,675 viajes\n",
      "  2016-09: 1,162,373 viajes\n",
      "  2016-10: 1,252,572 viajes\n",
      "  2016-11: 1,148,214 viajes\n",
      "  2016-12: 1,224,158 viajes\n",
      "  2017-01: 1,069,565 viajes\n",
      "  2017-02: 1,022,313 viajes\n",
      "  2017-03: 1,157,827 viajes\n",
      "  2017-04: 1,080,844 viajes\n",
      "  2017-05: 1,059,463 viajes\n",
      "  2017-06: 976,467 viajes\n",
      "  2017-07: 914,783 viajes\n",
      "  2017-08: 867,407 viajes\n",
      "  2017-09: 882,464 viajes\n",
      "  2017-10: 925,737 viajes\n",
      "  2017-11: 874,173 viajes\n",
      "  2017-12: 906,016 viajes\n",
      "  2018-01: 792,744 viajes\n",
      "  2018-02: 769,197 viajes\n",
      "  2018-03: 836,246 viajes\n",
      "  2018-04: 799,383 viajes\n",
      "  2018-05: 796,552 viajes\n",
      "  2018-06: 738,546 viajes\n",
      "  2018-07: 684,374 viajes\n",
      "  2018-08: 675,815 viajes\n",
      "  2018-09: 682,032 viajes\n",
      "  2018-10: 731,888 viajes\n",
      "  2018-11: 673,287 viajes\n",
      "  2018-12: 719,654 viajes\n",
      "  2019-01: 672,105 viajes\n",
      "  2019-02: 615,594 viajes\n",
      "  2019-03: 643,063 viajes\n",
      "  2019-04: 567,852 viajes\n",
      "  2019-05: 545,452 viajes\n",
      "  2019-06: 506,238 viajes\n",
      "  2019-07: 470,743 viajes\n",
      "  2019-08: 449,695 viajes\n",
      "  2019-09: 449,063 viajes\n",
      "  2019-10: 476,386 viajes\n",
      "  2019-11: 449,500 viajes\n",
      "  2019-12: 455,294 viajes\n",
      "  2020-01: 447,770 viajes\n",
      "  2020-02: 398,632 viajes\n",
      "  2020-03: 223,496 viajes\n",
      "  2020-04: 35,644 viajes\n",
      "  2020-05: 57,361 viajes\n",
      "  2020-06: 63,110 viajes\n",
      "  2020-07: 72,258 viajes\n",
      "  2020-08: 81,063 viajes\n",
      "  2020-09: 87,987 viajes\n",
      "  2020-10: 95,120 viajes\n",
      "  2020-11: 88,605 viajes\n",
      "  2020-12: 83,130 viajes\n",
      "  2021-01: 76,518 viajes\n",
      "  2021-02: 64,572 viajes\n",
      "  2021-03: 83,827 viajes\n",
      "  2021-04: 86,941 viajes\n",
      "  2021-05: 88,180 viajes\n",
      "  2021-06: 86,737 viajes\n",
      "  2021-07: 83,691 viajes\n",
      "  2021-08: 83,499 viajes\n",
      "  2021-09: 95,709 viajes\n",
      "  2021-10: 110,891 viajes\n",
      "  2021-11: 108,229 viajes\n",
      "  2021-12: 99,961 viajes\n",
      "  2022-01: 62,495 viajes\n",
      "  2022-02: 69,399 viajes\n",
      "  2022-03: 78,537 viajes\n",
      "  2022-04: 76,136 viajes\n",
      "  2022-05: 76,891 viajes\n",
      "  2022-06: 73,718 viajes\n",
      "  2022-07: 64,192 viajes\n",
      "  2022-08: 65,929 viajes\n",
      "  2022-09: 69,031 viajes\n",
      "  2022-10: 69,322 viajes\n",
      "  2022-11: 62,313 viajes\n",
      "  2022-12: 72,439 viajes\n",
      "  2023-01: 68,211 viajes\n",
      "  2023-02: 64,809 viajes\n",
      "  2023-03: 72,044 viajes\n",
      "  2023-04: 65,392 viajes\n",
      "  2023-05: 69,174 viajes\n",
      "  2023-06: 65,550 viajes\n",
      "  2023-07: 61,343 viajes\n",
      "  2023-08: 60,649 viajes\n",
      "  2023-09: 65,471 viajes\n",
      "  2023-10: 66,177 viajes\n",
      "  2023-11: 64,025 viajes\n",
      "  2023-12: 64,215 viajes\n",
      "  2024-01: 56,551 viajes\n",
      "  2024-02: 53,577 viajes\n",
      "  2024-03: 57,457 viajes\n",
      "  2024-04: 56,471 viajes\n",
      "  2024-05: 61,003 viajes\n",
      "  2024-06: 54,748 viajes\n",
      "  2024-07: 51,837 viajes\n",
      "  2024-08: 51,771 viajes\n",
      "  2024-09: 54,440 viajes\n",
      "  2024-10: 56,147 viajes\n",
      "  2024-11: 52,222 viajes\n",
      "  2024-12: 53,994 viajes\n",
      "  2025-01: 48,326 viajes\n",
      "  2025-02: 46,621 viajes\n",
      "  2025-03: 51,539 viajes\n",
      "  2025-04: 52,132 viajes\n",
      "  2025-05: 55,399 viajes\n",
      "  2025-06: 49,390 viajes\n",
      "  2025-07: 48,205 viajes\n",
      "  2025-08: 46,306 viajes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RESUMEN DE AUDITORÍA (ÚLTIMO ESTADO POR ARCHIVO)\n",
      "--------------------------------------------------------------------------------\n",
      "  SUCCESS: 256 archivos | 852,432,673 filas | 131.39s promedio\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ESTADO ACTUAL POR SERVICIO\n",
      "--------------------------------------------------------------------------------\n",
      "  GREEN - SUCCESS: 128 archivos | 68,045,597 filas\n",
      "  YELLOW - SUCCESS: 128 archivos | 784,387,076 filas\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "MATRIZ DE COBERTURA 2015-2025\n",
      "--------------------------------------------------------------------------------\n",
      "Leyenda: ✓ = Cargado | ✗ = Fallido | - = No disponible\n",
      "\n",
      "\n",
      "YELLOW:\n",
      "Año  | Ene Feb Mar Abr May Jun Jul Ago Sep Oct Nov Dic\n",
      "-----|------------------------------------------------\n",
      "2015 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2016 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2017 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2018 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2019 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2020 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2021 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2022 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2023 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2024 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2025 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  -  -  -  - \n",
      "\n",
      "GREEN:\n",
      "Año  | Ene Feb Mar Abr May Jun Jul Ago Sep Oct Nov Dic\n",
      "-----|------------------------------------------------\n",
      "2015 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2016 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2017 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2018 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2019 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2020 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2021 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2022 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2023 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2024 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓ \n",
      "2025 |  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  -  -  -  - \n",
      "\n",
      "================================================================================\n",
      "NOTEBOOK 01_INGESTA_PARQUET_RAW.IPYNB COMPLETADO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Genera reportes completos sobre:\n",
    "# 1. Conteos totales en tablas RAW.\n",
    "# 2. Distribución por año/mes/servicio.\n",
    "# 3. Resumen de auditoría (solo estado actual).\n",
    "# 4. Últimos intentos de carga.\n",
    "\n",
    "import os\n",
    "import snowflake.connector\n",
    "\n",
    "# Conectar a Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.environ[\"SNOWFLAKE_USER\"],\n",
    "    password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "    account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "    database=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    schema=os.environ[\"SNOWFLAKE_SCHEMA_RAW\"],\n",
    "    role=os.environ[\"SNOWFLAKE_ROLE\"],\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICACIÓN DE DATOS EN SNOWFLAKE RAW\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# CONTEOS TOTALES POR TABLA\n",
    "print(\"CONTEOS TOTALES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "cursor.execute(\"SELECT COUNT(*) FROM RAW_YELLOW_TRIPS\")\n",
    "yellow_count = cursor.fetchone()[0]\n",
    "print(f\"RAW_YELLOW_TRIPS: {yellow_count:,} filas\")\n",
    "\n",
    "cursor.execute(\"SELECT COUNT(*) FROM RAW_GREEN_TRIPS\")\n",
    "green_count = cursor.fetchone()[0]\n",
    "print(f\"RAW_GREEN_TRIPS:  {green_count:,} filas\")\n",
    "\n",
    "print(f\"TOTAL GENERAL:    {yellow_count + green_count:,} filas\")\n",
    "\n",
    "# DISTRIBUCIÓN YELLOW POR AÑO/MES\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"DISTRIBUCIÓN YELLOW (año-mes)\")\n",
    "print(\"-\"*80)\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT SOURCE_YEAR, SOURCE_MONTH, COUNT(*) AS cnt\n",
    "    FROM RAW_YELLOW_TRIPS\n",
    "    GROUP BY SOURCE_YEAR, SOURCE_MONTH\n",
    "    ORDER BY SOURCE_YEAR, SOURCE_MONTH\n",
    "\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "if not rows:\n",
    "    print(\"  (sin datos)\")\n",
    "else:\n",
    "    for row in rows:\n",
    "        print(f\"  {int(row[0])}-{int(row[1]):02d}: {int(row[2]):,} viajes\")\n",
    "\n",
    "# DISTRIBUCIÓN GREEN POR AÑO/MES\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"DISTRIBUCIÓN GREEN (año-mes)\")\n",
    "print(\"-\"*80)\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT SOURCE_YEAR, SOURCE_MONTH, COUNT(*) AS cnt\n",
    "    FROM RAW_GREEN_TRIPS\n",
    "    GROUP BY SOURCE_YEAR, SOURCE_MONTH\n",
    "    ORDER BY SOURCE_YEAR, SOURCE_MONTH\n",
    "\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "if not rows:\n",
    "    print(\"  (sin datos)\")\n",
    "else:\n",
    "    for row in rows:\n",
    "        print(f\"  {int(row[0])}-{int(row[1]):02d}: {int(row[2]):,} viajes\")\n",
    "\n",
    "# RESUMEN DE AUDITORÍA - SOLO ÚLTIMO ESTADO POR ARCHIVO\n",
    "# - Usa ROW_NUMBER para obtener solo el intento más reciente de cada archivo\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"RESUMEN DE AUDITORÍA (ÚLTIMO ESTADO POR ARCHIVO)\")\n",
    "print(\"-\"*80)\n",
    "cursor.execute(\"\"\"\n",
    "    WITH LastAttempt AS (\n",
    "        SELECT \n",
    "            SERVICE_TYPE,\n",
    "            SOURCE_YEAR,\n",
    "            SOURCE_MONTH,\n",
    "            STATUS,\n",
    "            ROWS_PROCESSED,\n",
    "            PROCESSING_TIME_SECONDS,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY SERVICE_TYPE, SOURCE_YEAR, SOURCE_MONTH \n",
    "                ORDER BY CREATED_AT DESC\n",
    "            ) AS rn\n",
    "        FROM INGESTA_AUDIT\n",
    "    )\n",
    "    SELECT \n",
    "        STATUS,\n",
    "        COUNT(*) AS cnt,\n",
    "        COALESCE(SUM(ROWS_PROCESSED), 0) AS total_rows,\n",
    "        COALESCE(AVG(PROCESSING_TIME_SECONDS), 0) AS avg_time\n",
    "    FROM LastAttempt\n",
    "    WHERE rn = 1\n",
    "    GROUP BY STATUS\n",
    "    ORDER BY STATUS\n",
    "\"\"\")\n",
    "\n",
    "audit_summary = cursor.fetchall()\n",
    "if not audit_summary:\n",
    "    print(\"  (sin registros de auditoría)\")\n",
    "else:\n",
    "    for status, cnt, total_rows, avg_time in audit_summary:\n",
    "        print(f\"  {status}: {cnt} archivos | {int(total_rows):,} filas | {float(avg_time):.2f}s promedio\")\n",
    "\n",
    "# ESTADO ACTUAL POR SERVICIO\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ESTADO ACTUAL POR SERVICIO\")\n",
    "print(\"-\"*80)\n",
    "cursor.execute(\"\"\"\n",
    "    WITH LastAttempt AS (\n",
    "        SELECT \n",
    "            SERVICE_TYPE,\n",
    "            SOURCE_YEAR,\n",
    "            SOURCE_MONTH,\n",
    "            STATUS,\n",
    "            ROWS_PROCESSED,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY SERVICE_TYPE, SOURCE_YEAR, SOURCE_MONTH \n",
    "                ORDER BY CREATED_AT DESC\n",
    "            ) AS rn\n",
    "        FROM INGESTA_AUDIT\n",
    "    )\n",
    "    SELECT \n",
    "        SERVICE_TYPE,\n",
    "        STATUS,\n",
    "        COUNT(*) AS archivos,\n",
    "        SUM(ROWS_PROCESSED) AS total_rows\n",
    "    FROM LastAttempt\n",
    "    WHERE rn = 1\n",
    "    GROUP BY SERVICE_TYPE, STATUS\n",
    "    ORDER BY SERVICE_TYPE, STATUS\n",
    "\"\"\")\n",
    "\n",
    "service_status = cursor.fetchall()\n",
    "if not service_status:\n",
    "    print(\"  (sin datos)\")\n",
    "else:\n",
    "    for svc, status, cnt, total_rows in service_status:\n",
    "        total_rows = total_rows or 0\n",
    "        print(f\"  {svc.upper()} - {status}: {cnt} archivos | {int(total_rows):,} filas\")\n",
    "\n",
    "# MATRIZ DE COBERTURA\n",
    "# - Muestra qué meses están disponibles por año y servicio\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MATRIZ DE COBERTURA 2015-2025\")\n",
    "print(\"-\"*80)\n",
    "print(\"Leyenda: ✓ = Cargado | ✗ = Fallido | - = No disponible\\n\")\n",
    "\n",
    "# Obtener datos de cobertura\n",
    "cursor.execute(\"\"\"\n",
    "    WITH LastAttempt AS (\n",
    "        SELECT \n",
    "            SERVICE_TYPE,\n",
    "            SOURCE_YEAR,\n",
    "            SOURCE_MONTH,\n",
    "            STATUS,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY SERVICE_TYPE, SOURCE_YEAR, SOURCE_MONTH \n",
    "                ORDER BY CREATED_AT DESC\n",
    "            ) AS rn\n",
    "        FROM INGESTA_AUDIT\n",
    "    )\n",
    "    SELECT \n",
    "        SERVICE_TYPE,\n",
    "        SOURCE_YEAR,\n",
    "        SOURCE_MONTH,\n",
    "        STATUS\n",
    "    FROM LastAttempt\n",
    "    WHERE rn = 1\n",
    "    ORDER BY SERVICE_TYPE, SOURCE_YEAR, SOURCE_MONTH\n",
    "\"\"\")\n",
    "\n",
    "coverage_data = {}\n",
    "for svc, yr, mn, st in cursor.fetchall():\n",
    "    key = f\"{svc}_{yr}\"\n",
    "    if key not in coverage_data:\n",
    "        coverage_data[key] = {}\n",
    "    coverage_data[key][mn] = st\n",
    "\n",
    "# Imprimir matriz\n",
    "for service in ['yellow', 'green']:\n",
    "    print(f\"\\n{service.upper()}:\")\n",
    "    print(\"Año  | Ene Feb Mar Abr May Jun Jul Ago Sep Oct Nov Dic\")\n",
    "    print(\"-----|\" + \"-\" * 48)\n",
    "    \n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        key = f\"{service}_{year}\"\n",
    "        months_str = []\n",
    "        \n",
    "        for month in range(1, 13):\n",
    "            # No mostrar meses futuros\n",
    "            if year == MAX_YEAR and month > MAX_MONTH:\n",
    "                months_str.append(\" - \")\n",
    "            elif key in coverage_data and month in coverage_data[key]:\n",
    "                status = coverage_data[key][month]\n",
    "                symbol = \" ✓ \" if status == \"SUCCESS\" else \" ✗ \"\n",
    "                months_str.append(symbol)\n",
    "            else:\n",
    "                months_str.append(\" - \")\n",
    "        \n",
    "        print(f\"{year} | {''.join(months_str)}\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NOTEBOOK 01_INGESTA_PARQUET_RAW.IPYNB COMPLETADO\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
