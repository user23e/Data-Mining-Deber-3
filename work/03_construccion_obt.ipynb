{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c7ed56-7350-4c76-ba7a-421f71b99d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowflake-connector-python\n",
      "  Downloading snowflake_connector_python-4.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow in /opt/conda/lib/python3.11/site-packages (13.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.0.3)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python)\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (41.0.4)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (23.2.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2023.3.post1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (23.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (4.8.0)\n",
      "Collecting filelock<4,>=3.5 (from snowflake-connector-python)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.11.0)\n",
      "Collecting tomlkit (from snowflake-connector-python)\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting boto3>=1.24 (from snowflake-connector-python)\n",
      "  Downloading boto3-1.40.55-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore>=1.24 (from snowflake-connector-python)\n",
      "  Downloading botocore-1.40.55-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.11/site-packages (from pyarrow) (1.24.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.24->snowflake-connector-python)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3>=1.24->snowflake-connector-python)\n",
      "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.1.0->snowflake-connector-python) (1.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.1.0->snowflake-connector-python) (2.21)\n",
      "Downloading snowflake_connector_python-4.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.40.55-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.40.55-py3-none-any.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: asn1crypto, tomlkit, jmespath, filelock, botocore, s3transfer, boto3, snowflake-connector-python\n",
      "Successfully installed asn1crypto-1.5.1 boto3-1.40.55 botocore-1.40.55 filelock-3.20.0 jmespath-1.0.1 s3transfer-0.14.0 snowflake-connector-python-4.0.0 tomlkit-0.13.3\n",
      "================================================================================\n",
      "Paquetes instalados correctamente.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Instalar las librerías necesarias.\n",
    "\n",
    "!pip install snowflake-connector-python pyarrow requests pandas\n",
    "print(\"=\" * 80)\n",
    "print(\"Paquetes instalados correctamente.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2b47de-69ce-40c9-b8bf-5d4f3423693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONFIGURACIÓN DE AMBIENTE - PROYECTO 3\n",
      "================================================================================\n",
      "Todas las variables de ambiente requeridas están configuradas.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verificar que todas las variables de ambiente necesarias estén configuradas.\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from io import StringIO\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import snowflake.connector\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CONFIGURACIÓN DE AMBIENTE - PROYECTO 3\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Variables obligatorias\n",
    "required_vars = [\n",
    "    'SNOWFLAKE_ACCOUNT',\n",
    "    'SNOWFLAKE_DATABASE',\n",
    "    'SNOWFLAKE_SCHEMA_RAW',\n",
    "    'SNOWFLAKE_SCHEMA_ANALYTICS',\n",
    "    'SNOWFLAKE_WAREHOUSE',\n",
    "    'SNOWFLAKE_USER',\n",
    "    'SNOWFLAKE_PASSWORD',\n",
    "    'SNOWFLAKE_ROLE',\n",
    "    'TAXI_ZONE_URL'\n",
    "]\n",
    "\n",
    "# Verificar que todas las variables existan\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    print(f\"ERROR: Faltan variables de ambiente: {', '.join(missing_vars)}\")\n",
    "    print(\"Por favor configura tu archivo .env correctamente.\")\n",
    "else:\n",
    "    print(\"Todas las variables de ambiente requeridas están configuradas.\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09887bb5-5b68-4ba6-a686-fa70071124d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SPARK SESSION CREADA EXITOSAMENTE\n",
      "================================================================================\n",
      "Spark Version: 3.5.0\n",
      "Spark UI disponible en: http://localhost:4040\n",
      "Timezone: UTC\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Configura Spark para conectarse a Snowflake y procesar la OBT.\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"P3 - Construcción OBT - Anahi Andrade\")\n",
    "    \n",
    "    .config(\"spark.sql.timestampType\", \"TIMESTAMP_LTZ\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    \n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"net.snowflake:snowflake-jdbc:3.13.33,\"\n",
    "        \"net.snowflake:spark-snowflake_2.12:2.9.3-spark_3.1\"\n",
    "    )\n",
    "    \n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "    \n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SPARK SESSION CREADA EXITOSAMENTE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Spark UI disponible en: http://localhost:4040\")\n",
    "print(f\"Timezone: {spark.conf.get('spark.sql.session.timeZone')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "284b5c42-af48-4507-a83f-8cdc8d03befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Configuración Snowflake lista para usar.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Definir opciones de conexión a Snowflake para lectura/escritura con Spark.\n",
    "\n",
    "snowflake_options = {\n",
    "    \"sfURL\": f\"{os.getenv('SNOWFLAKE_ACCOUNT')}.snowflakecomputing.com\",\n",
    "    \"sfUser\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"sfPassword\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"sfDatabase\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"sfWarehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    \"sfRole\": os.getenv(\"SNOWFLAKE_ROLE\")\n",
    "}\n",
    "print(\"=\" * 80)\n",
    "print(\"Configuración Snowflake lista para usar.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68a9a99f-2a04-4255-b061-2eb15e19a393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREACIÓN DE TABLA ANALYTICS.OBT_TRIPS\n",
      "================================================================================\n",
      "Esquema ANALYTICS creado/verificado.\n",
      "Eliminando tabla OBT_TRIPS anterior (si existe).\n",
      "- Tabla anterior eliminada completamente.\n",
      "Tabla ANALYTICS.OBT_TRIPS creada con 45 columnas (incluye TRIP_ID).\n",
      "================================================================================\n",
      "VERIFICACIÓN EXITOSA: 45 columnas en OBT_TRIPS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Crear la tabla ANALYTICS.OBT_TRIPS.\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREACIÓN DE TABLA ANALYTICS.OBT_TRIPS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.environ[\"SNOWFLAKE_USER\"],\n",
    "    password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "    account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "    database=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    role=os.environ[\"SNOWFLAKE_ROLE\"]\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Crear esquema ANALYTICS si no existe\n",
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS ANALYTICS\")\n",
    "print(\"Esquema ANALYTICS creado/verificado.\")\n",
    "\n",
    "# Por si acaso eliminar tabla existente completamente\n",
    "print(\"Eliminando tabla OBT_TRIPS anterior (si existe).\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS ANALYTICS.OBT_TRIPS\")\n",
    "print(\"- Tabla anterior eliminada completamente.\")\n",
    "\n",
    "# Crear tabla OBT_TRIPS\n",
    "# - Incluye TRIP_ID como clave surrogada\n",
    "create_obt = \"\"\"\n",
    "CREATE TABLE ANALYTICS.OBT_TRIPS (\n",
    "    -- CLAVE SURROGADA: 1 campo\n",
    "    TRIP_ID VARCHAR(64),\n",
    "    \n",
    "    -- TIEMPO: 9 campos\n",
    "    PICKUP_DATETIME TIMESTAMP_NTZ,\n",
    "    DROPOFF_DATETIME TIMESTAMP_NTZ,\n",
    "    PICKUP_DATE DATE,\n",
    "    PICKUP_HOUR INTEGER,\n",
    "    DROPOFF_DATE DATE,\n",
    "    DROPOFF_HOUR INTEGER,\n",
    "    DAY_OF_WEEK INTEGER,\n",
    "    MONTH INTEGER,\n",
    "    YEAR INTEGER,\n",
    "    \n",
    "    -- UBICACIÓN: 6 campos\n",
    "    PU_LOCATION_ID BIGINT,\n",
    "    PU_ZONE VARCHAR(100),\n",
    "    PU_BOROUGH VARCHAR(50),\n",
    "    DO_LOCATION_ID BIGINT,\n",
    "    DO_ZONE VARCHAR(100),\n",
    "    DO_BOROUGH VARCHAR(50),\n",
    "    \n",
    "    -- SERVICIO Y CÓDIGOS: 9 campos\n",
    "    SERVICE_TYPE VARCHAR(10),\n",
    "    VENDOR_ID BIGINT,\n",
    "    VENDOR_NAME VARCHAR(100),\n",
    "    RATE_CODE_ID DOUBLE,\n",
    "    RATE_CODE_DESC VARCHAR(50),\n",
    "    PAYMENT_TYPE BIGINT,\n",
    "    PAYMENT_TYPE_DESC VARCHAR(50),\n",
    "    TRIP_TYPE BIGINT,\n",
    "    TRIP_TYPE_DESC VARCHAR(50),\n",
    "    \n",
    "    -- VIAJE: 3 campos\n",
    "    PASSENGER_COUNT DOUBLE,\n",
    "    TRIP_DISTANCE DOUBLE,\n",
    "    STORE_AND_FWD_FLAG VARCHAR(1),\n",
    "    \n",
    "    -- TARIFAS: 9 campos\n",
    "    FARE_AMOUNT DOUBLE,\n",
    "    EXTRA DOUBLE,\n",
    "    MTA_TAX DOUBLE,\n",
    "    TIP_AMOUNT DOUBLE,\n",
    "    TOLLS_AMOUNT DOUBLE,\n",
    "    IMPROVEMENT_SURCHARGE DOUBLE,\n",
    "    CONGESTION_SURCHARGE DOUBLE,\n",
    "    AIRPORT_FEE DOUBLE,\n",
    "    TOTAL_AMOUNT DOUBLE,\n",
    "    \n",
    "    -- DERIVADAS: 3 campos\n",
    "    TRIP_DURATION_MIN DOUBLE,\n",
    "    AVG_SPEED_MPH DOUBLE,\n",
    "    TIP_PCT DOUBLE,\n",
    "    \n",
    "    -- LINEAGE/CALIDAD: 5 campos\n",
    "    RUN_ID INTEGER,\n",
    "    INGESTED_AT_UTC TIMESTAMP_NTZ,\n",
    "    SOURCE_SERVICE VARCHAR(10),\n",
    "    SOURCE_YEAR INTEGER,\n",
    "    SOURCE_MONTH INTEGER\n",
    ") CLUSTER BY (TRIP_ID)\n",
    "\"\"\"\n",
    "cursor.execute(create_obt)\n",
    "print(\"Tabla ANALYTICS.OBT_TRIPS creada con 45 columnas (incluye TRIP_ID).\")\n",
    "\n",
    "# Verificar estructura - DEBE mostrar 45\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "    WHERE TABLE_SCHEMA = 'ANALYTICS' \n",
    "      AND TABLE_NAME = 'OBT_TRIPS'\n",
    "\"\"\")\n",
    "col_count = cursor.fetchone()[0]\n",
    "print(\"=\" * 80)\n",
    "if col_count == 45:\n",
    "    print(f\"VERIFICACIÓN EXITOSA: {col_count} columnas en OBT_TRIPS\")\n",
    "else:\n",
    "    print(f\"ERROR: Se esperaban 45 columnas pero hay {col_count}\")\n",
    "    print(\"Ejecuta nuevamente esta celda para corregir.\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3909cab-989b-48aa-bd7a-f73623a9d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONSTRUCCIÓN DE OBT\n",
      "================================================================================\n",
      "Limpiando tabla ANALYTICS.OBT_TRIPS...\n",
      "Ejecutando construcción de OBT...\n",
      "================================================================================\n",
      "OBT construida exitosamente en 1034 segundos: 889,971,027 filas\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Construir la OBT desde CLEAN.UNIFIED_TRIPS agregando:\n",
    "# 1. Campos temporales derivados (fecha, hora, día de semana).\n",
    "# 2. Campos calculados (duración, velocidad promedio, % propina).\n",
    "# 3. TRIP_ID como clave surrogada (hash SHA2-256).\n",
    "# NOTA: Se ejecuta en Snowflake para mejor performance con ~890M filas.\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONSTRUCCIÓN DE OBT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Inicio del cronómetro\n",
    "start_time = time.time()\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.environ[\"SNOWFLAKE_USER\"],\n",
    "    password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "    account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "    database=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    role=os.environ[\"SNOWFLAKE_ROLE\"]\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Truncar para idempotencia\n",
    "print(\"Limpiando tabla ANALYTICS.OBT_TRIPS...\")\n",
    "cursor.execute(\"TRUNCATE TABLE ANALYTICS.OBT_TRIPS\")\n",
    "\n",
    "# INSERT con transformaciones y campos derivados\n",
    "build_obt = \"\"\"\n",
    "INSERT INTO ANALYTICS.OBT_TRIPS\n",
    "SELECT\n",
    "    -- Clave surrogada: hash SHA2-256 de campos naturales\n",
    "    SHA2(\n",
    "        CONCAT(\n",
    "            COALESCE(TO_VARCHAR(PICKUP_DATETIME), ''),\n",
    "            '|',\n",
    "            COALESCE(TO_VARCHAR(DROPOFF_DATETIME), ''),\n",
    "            '|',\n",
    "            COALESCE(TO_VARCHAR(PULOCATIONID), ''),\n",
    "            '|',\n",
    "            COALESCE(TO_VARCHAR(DOLOCATIONID), ''),\n",
    "            '|',\n",
    "            COALESCE(TO_VARCHAR(VENDORID), ''),\n",
    "            '|',\n",
    "            COALESCE(SERVICE_TYPE, '')\n",
    "        ),\n",
    "        256\n",
    "    ) AS TRIP_ID,\n",
    "    \n",
    "    -- Tiempo (campos base)\n",
    "    PICKUP_DATETIME,\n",
    "    DROPOFF_DATETIME,\n",
    "    \n",
    "    -- Tiempo (campos derivados)\n",
    "    DATE(PICKUP_DATETIME) AS PICKUP_DATE,\n",
    "    HOUR(PICKUP_DATETIME) AS PICKUP_HOUR,\n",
    "    DATE(DROPOFF_DATETIME) AS DROPOFF_DATE,\n",
    "    HOUR(DROPOFF_DATETIME) AS DROPOFF_HOUR,\n",
    "    DAYOFWEEK(PICKUP_DATETIME) AS DAY_OF_WEEK,\n",
    "    MONTH(PICKUP_DATETIME) AS MONTH,\n",
    "    YEAR(PICKUP_DATETIME) AS YEAR,\n",
    "    \n",
    "    -- Ubicación\n",
    "    PULOCATIONID AS PU_LOCATION_ID,\n",
    "    PU_ZONE,\n",
    "    PU_BOROUGH,\n",
    "    DOLOCATIONID AS DO_LOCATION_ID,\n",
    "    DO_ZONE,\n",
    "    DO_BOROUGH,\n",
    "    \n",
    "    -- Servicio y códigos\n",
    "    SERVICE_TYPE,\n",
    "    VENDORID AS VENDOR_ID,\n",
    "    VENDOR_NAME,\n",
    "    RATECODEID AS RATE_CODE_ID,\n",
    "    RATE_CODE_DESC,\n",
    "    PAYMENT_TYPE,\n",
    "    PAYMENT_TYPE_DESC,\n",
    "    TRIP_TYPE,\n",
    "    TRIP_TYPE_DESC,\n",
    "    \n",
    "    -- Métricas del viaje\n",
    "    PASSENGER_COUNT,\n",
    "    TRIP_DISTANCE,\n",
    "    STORE_AND_FWD_FLAG,\n",
    "    \n",
    "    -- Tarifas\n",
    "    FARE_AMOUNT,\n",
    "    EXTRA,\n",
    "    MTA_TAX,\n",
    "    TIP_AMOUNT,\n",
    "    TOLLS_AMOUNT,\n",
    "    IMPROVEMENT_SURCHARGE,\n",
    "    CONGESTION_SURCHARGE,\n",
    "    AIRPORT_FEE,\n",
    "    TOTAL_AMOUNT,\n",
    "    \n",
    "    -- Campos derivados calculados\n",
    "    CASE \n",
    "        WHEN PICKUP_DATETIME IS NULL OR DROPOFF_DATETIME IS NULL THEN NULL\n",
    "        WHEN DATEDIFF('second', PICKUP_DATETIME, DROPOFF_DATETIME) < 0 THEN NULL\n",
    "        ELSE DATEDIFF('second', PICKUP_DATETIME, DROPOFF_DATETIME) / 60.0\n",
    "    END AS TRIP_DURATION_MIN,\n",
    "    \n",
    "    -- Velocidad promedio en mph (manejo de división por cero)\n",
    "    CASE \n",
    "        WHEN TRIP_DISTANCE IS NULL OR TRIP_DISTANCE <= 0 THEN NULL\n",
    "        WHEN PICKUP_DATETIME IS NULL OR DROPOFF_DATETIME IS NULL THEN NULL\n",
    "        WHEN DATEDIFF('second', PICKUP_DATETIME, DROPOFF_DATETIME) <= 0 THEN NULL\n",
    "        ELSE (TRIP_DISTANCE / (DATEDIFF('second', PICKUP_DATETIME, DROPOFF_DATETIME) / 3600.0))\n",
    "    END AS AVG_SPEED_MPH,\n",
    "    \n",
    "    -- Porcentaje de propina (manejo de división por cero)\n",
    "    CASE \n",
    "        WHEN FARE_AMOUNT IS NULL OR FARE_AMOUNT <= 0 THEN NULL\n",
    "        WHEN TIP_AMOUNT IS NULL THEN NULL\n",
    "        ELSE (TIP_AMOUNT / FARE_AMOUNT) * 100.0\n",
    "    END AS TIP_PCT,\n",
    "    \n",
    "    -- Lineage\n",
    "    RUN_ID,\n",
    "    INGESTED_AT_UTC,\n",
    "    SERVICE_TYPE AS SOURCE_SERVICE,\n",
    "    SOURCE_YEAR,\n",
    "    SOURCE_MONTH\n",
    "    \n",
    "FROM CLEAN.UNIFIED_TRIPS\n",
    "WHERE PICKUP_DATETIME IS NOT NULL \n",
    "  AND DROPOFF_DATETIME IS NOT NULL\n",
    "  AND PULOCATIONID IS NOT NULL\n",
    "  AND DOLOCATIONID IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "print(\"Ejecutando construcción de OBT...\")\n",
    "cursor.execute(build_obt)\n",
    "\n",
    "# Auditoría final\n",
    "cursor.execute(\"SELECT COUNT(*) FROM ANALYTICS.OBT_TRIPS\")\n",
    "count = cursor.fetchone()[0]\n",
    "\n",
    "# Calcular tiempo transcurrido\n",
    "elapsed_seconds = int(time.time() - start_time)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"OBT construida exitosamente en {elapsed_seconds} segundos: {count:,} filas\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "651a5d99-dcc9-4e89-8179-aadd411b4f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CALIDAD DE DATOS\n",
      "================================================================================\n",
      "\n",
      "--- Verificación de nulos en columnas críticas ---\n",
      "  Pickup DateTime nulos: 0 (0.00%)\n",
      "  Dropoff DateTime nulos: 0 (0.00%)\n",
      "  PU Location nulos: 0 (0.00%)\n",
      "  DO Location nulos: 0 (0.00%)\n",
      "  Total Amount nulos: 0 (0.00%)\n",
      "\n",
      "--- Verificación de rangos lógicos ---\n",
      "  Trip Distance: min=-40840124.40, max=59016609.30\n",
      "  Trip Duration: min=0.00, max=125373160.83\n",
      "  Total Amount: min=$-2567.80, max=$3950611.60\n",
      "\n",
      "--- Verificación de coherencia de fechas ---\n",
      "  Viajes con pickup > dropoff: 88,386\n",
      "\n",
      "--- Verificación de valores negativos ---\n",
      "  Fare Amount negativos: 3,991,198\n",
      "  Tip Amount negativos: 19,430\n",
      "  Total Amount negativos: 2,647,231\n",
      "\n",
      "====================================================================================================\n",
      "Como se puede observar, se tiene que realizar limpieza de datos, esto se realizará en el NOTEBOOK 4.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Observar calidad de datos en ANALYTICS.OBT_TRIPS.\n",
    "# - Verifica nulos en columnas críticas, rangos lógicos y coherencia.\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CALIDAD DE DATOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.environ[\"SNOWFLAKE_USER\"],\n",
    "    password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "    account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "    database=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    role=os.environ[\"SNOWFLAKE_ROLE\"]\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 1. Verificar nulos en columnas críticas\n",
    "print(\"\\n--- Verificación de nulos en columnas críticas ---\")\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT \n",
    "        SUM(CASE WHEN PICKUP_DATETIME IS NULL THEN 1 ELSE 0 END) AS null_pickup,\n",
    "        SUM(CASE WHEN DROPOFF_DATETIME IS NULL THEN 1 ELSE 0 END) AS null_dropoff,\n",
    "        SUM(CASE WHEN PU_LOCATION_ID IS NULL THEN 1 ELSE 0 END) AS null_pu_loc,\n",
    "        SUM(CASE WHEN DO_LOCATION_ID IS NULL THEN 1 ELSE 0 END) AS null_do_loc,\n",
    "        SUM(CASE WHEN TOTAL_AMOUNT IS NULL THEN 1 ELSE 0 END) AS null_total,\n",
    "        COUNT(*) AS total\n",
    "    FROM ANALYTICS.OBT_TRIPS\n",
    "\"\"\")\n",
    "row = cursor.fetchone()\n",
    "total = row[5] if row[5] > 0 else 1\n",
    "print(f\"  Pickup DateTime nulos: {row[0]:,} ({row[0]/total*100:.2f}%)\")\n",
    "print(f\"  Dropoff DateTime nulos: {row[1]:,} ({row[1]/total*100:.2f}%)\")\n",
    "print(f\"  PU Location nulos: {row[2]:,} ({row[2]/total*100:.2f}%)\")\n",
    "print(f\"  DO Location nulos: {row[3]:,} ({row[3]/total*100:.2f}%)\")\n",
    "print(f\"  Total Amount nulos: {row[4]:,} ({row[4]/total*100:.2f}%)\")\n",
    "\n",
    "# 2. Verificar rangos lógicos\n",
    "print(\"\\n--- Verificación de rangos lógicos ---\")\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT \n",
    "        MIN(TRIP_DISTANCE) AS min_dist,\n",
    "        MAX(TRIP_DISTANCE) AS max_dist,\n",
    "        MIN(TRIP_DURATION_MIN) AS min_dur,\n",
    "        MAX(TRIP_DURATION_MIN) AS max_dur,\n",
    "        MIN(TOTAL_AMOUNT) AS min_amt,\n",
    "        MAX(TOTAL_AMOUNT) AS max_amt\n",
    "    FROM ANALYTICS.OBT_TRIPS\n",
    "    WHERE TRIP_DISTANCE IS NOT NULL\n",
    "      AND TRIP_DURATION_MIN IS NOT NULL\n",
    "      AND TOTAL_AMOUNT IS NOT NULL\n",
    "\"\"\")\n",
    "row = cursor.fetchone()\n",
    "if row:\n",
    "    print(f\"  Trip Distance: min={row[0]:.2f}, max={row[1]:.2f}\")\n",
    "    print(f\"  Trip Duration: min={row[2]:.2f}, max={row[3]:.2f}\")\n",
    "    print(f\"  Total Amount: min=${row[4]:.2f}, max=${row[5]:.2f}\")\n",
    "\n",
    "# 3. Verificar coherencia de fechas\n",
    "print(\"\\n--- Verificación de coherencia de fechas ---\")\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM ANALYTICS.OBT_TRIPS\n",
    "    WHERE PICKUP_DATETIME > DROPOFF_DATETIME\n",
    "\"\"\")\n",
    "invalid_dates = cursor.fetchone()[0]\n",
    "print(f\"  Viajes con pickup > dropoff: {invalid_dates:,}\")\n",
    "\n",
    "# 4. Verificar valores negativos en tarifas\n",
    "print(\"\\n--- Verificación de valores negativos ---\")\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT \n",
    "        SUM(CASE WHEN FARE_AMOUNT < 0 THEN 1 ELSE 0 END) AS neg_fare,\n",
    "        SUM(CASE WHEN TIP_AMOUNT < 0 THEN 1 ELSE 0 END) AS neg_tip,\n",
    "        SUM(CASE WHEN TOTAL_AMOUNT < 0 THEN 1 ELSE 0 END) AS neg_total\n",
    "    FROM ANALYTICS.OBT_TRIPS\n",
    "\"\"\")\n",
    "row = cursor.fetchone()\n",
    "print(f\"  Fare Amount negativos: {row[0]:,}\")\n",
    "print(f\"  Tip Amount negativos: {row[1]:,}\")\n",
    "print(f\"  Total Amount negativos: {row[2]:,}\")\n",
    "\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Como se puede observar, se tiene que realizar limpieza de datos, esto se realizará en el NOTEBOOK 4.\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f34c4f2-3cce-450f-a0ad-d12b9bb4f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PRUEBA DE IDEMPOTENCIA CON UPSERT (CLAVE SURROGADA)\n",
      "================================================================================\n",
      "Mes de prueba: YELLOW 2020-04\n",
      "Antes de UPSERT: 238,073 filas para yellow 2020-04\n",
      "\n",
      "Ejecutando MERGE (UPSERT) con clave surrogada TRIP_ID...\n",
      "Despues de UPSERT: 238,073 filas para yellow 2020-04\n",
      "\n",
      "--- Resultado de idempotencia ---\n",
      "IDEMPOTENCIA VERIFICADA: 238,073 = 238,073\n",
      "El MERGE actualizo filas existentes sin duplicar.\n",
      "\n",
      "Prueba completada en 35 segundos.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Prueba de idempotencia: reingestar un mes específico usando UPSERT.\n",
    "# - Esta celda demuestra que reingestar el mismo mes NO duplica datos.\n",
    "\n",
    "# ESTRATEGIA: Usamos MERGE (UPSERT) basado en clave surrogada (TRIP_ID).\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRUEBA DE IDEMPOTENCIA CON UPSERT (CLAVE SURROGADA)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Inicio del cronómetro\n",
    "start_time = time.time()\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.environ[\"SNOWFLAKE_USER\"],\n",
    "    password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "    account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "    database=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    role=os.environ[\"SNOWFLAKE_ROLE\"]\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Parámetros de prueba (usar un mes con pocos datos para que sea rápido)\n",
    "TEST_YEAR = 2020\n",
    "TEST_MONTH = 4  # Abril 2020 (COVID - bajo volumen)\n",
    "TEST_SERVICE = 'yellow'\n",
    "\n",
    "print(f\"Mes de prueba: {TEST_SERVICE.upper()} {TEST_YEAR}-{TEST_MONTH:02d}\")\n",
    "\n",
    "# 1. Contar filas actuales en OBT para este mes\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM ANALYTICS.OBT_TRIPS\n",
    "    WHERE SOURCE_YEAR = {TEST_YEAR}\n",
    "      AND SOURCE_MONTH = {TEST_MONTH}\n",
    "      AND SOURCE_SERVICE = '{TEST_SERVICE}'\n",
    "\"\"\")\n",
    "count_before = cursor.fetchone()[0]\n",
    "print(f\"Antes de UPSERT: {count_before:,} filas para {TEST_SERVICE} {TEST_YEAR}-{TEST_MONTH:02d}\")\n",
    "\n",
    "# 2. Ejecutar MERGE (UPSERT) para reingestar el mismo mes\n",
    "print(\"\\nEjecutando MERGE (UPSERT) con clave surrogada TRIP_ID...\")\n",
    "\n",
    "merge_sql = f\"\"\"\n",
    "MERGE INTO ANALYTICS.OBT_TRIPS AS target\n",
    "USING (\n",
    "    SELECT * FROM (\n",
    "        SELECT\n",
    "            -- Clave surrogada: hash SHA2-256 de campos naturales\n",
    "            SHA2(\n",
    "                CONCAT(\n",
    "                    COALESCE(TO_VARCHAR(PICKUP_DATETIME), ''),\n",
    "                    '|',\n",
    "                    COALESCE(TO_VARCHAR(DROPOFF_DATETIME), ''),\n",
    "                    '|',\n",
    "                    COALESCE(TO_VARCHAR(PULOCATIONID), ''),\n",
    "                    '|',\n",
    "                    COALESCE(TO_VARCHAR(DOLOCATIONID), ''),\n",
    "                    '|',\n",
    "                    COALESCE(TO_VARCHAR(VENDORID), ''),\n",
    "                    '|',\n",
    "                    COALESCE(SERVICE_TYPE, '')\n",
    "                ),\n",
    "                256\n",
    "            ) AS TRIP_ID,\n",
    "            \n",
    "            -- Tiempo\n",
    "            PICKUP_DATETIME,\n",
    "            DROPOFF_DATETIME,\n",
    "            DATE(PICKUP_DATETIME) AS PICKUP_DATE,\n",
    "            HOUR(PICKUP_DATETIME) AS PICKUP_HOUR,\n",
    "            DATE(DROPOFF_DATETIME) AS DROPOFF_DATE,\n",
    "            HOUR(DROPOFF_DATETIME) AS DROPOFF_HOUR,\n",
    "            DAYOFWEEK(PICKUP_DATETIME) AS DAY_OF_WEEK,\n",
    "            MONTH(PICKUP_DATETIME) AS MONTH,\n",
    "            YEAR(PICKUP_DATETIME) AS YEAR,\n",
    "            \n",
    "            -- Ubicacion\n",
    "            PULOCATIONID AS PU_LOCATION_ID,\n",
    "            PU_ZONE,\n",
    "            PU_BOROUGH,\n",
    "            DOLOCATIONID AS DO_LOCATION_ID,\n",
    "            DO_ZONE,\n",
    "            DO_BOROUGH,\n",
    "            \n",
    "            -- Servicio\n",
    "            SERVICE_TYPE,\n",
    "            VENDORID AS VENDOR_ID,\n",
    "            VENDOR_NAME,\n",
    "            RATECODEID AS RATE_CODE_ID,\n",
    "            RATE_CODE_DESC,\n",
    "            PAYMENT_TYPE,\n",
    "            PAYMENT_TYPE_DESC,\n",
    "            TRIP_TYPE,\n",
    "            TRIP_TYPE_DESC,\n",
    "            \n",
    "            -- Viaje\n",
    "            PASSENGER_COUNT,\n",
    "            TRIP_DISTANCE,\n",
    "            STORE_AND_FWD_FLAG,\n",
    "            \n",
    "            -- Tarifas\n",
    "            FARE_AMOUNT,\n",
    "            EXTRA,\n",
    "            MTA_TAX,\n",
    "            TIP_AMOUNT,\n",
    "            TOLLS_AMOUNT,\n",
    "            IMPROVEMENT_SURCHARGE,\n",
    "            CONGESTION_SURCHARGE,\n",
    "            AIRPORT_FEE,\n",
    "            TOTAL_AMOUNT,\n",
    "            \n",
    "            -- Derivadas\n",
    "            CASE \n",
    "                WHEN PICKUP_DATETIME IS NULL OR DROPOFF_DATETIME IS NULL THEN NULL\n",
    "                WHEN DATEDIFF('second', PICKUP_DATETIME, DROPOFF_DATETIME) < 0 THEN NULL\n",
    "                ELSE DATEDIFF('second', PICKUP_DATETIME, DROPOFF_DATETIME) / 60.0\n",
    "            END AS TRIP_DURATION_MIN,\n",
    "            CASE \n",
    "                WHEN TRIP_DISTANCE IS NULL OR TRIP_DISTANCE <= 0 THEN NULL\n",
    "                WHEN PICKUP_DATETIME IS NULL OR DROPOFF_DATETIME IS NULL THEN NULL\n",
    "                WHEN DATEDIFF('second', PICKUP_DATETIME, DROPOFF_DATETIME) <= 0 THEN NULL\n",
    "                ELSE (TRIP_DISTANCE / (DATEDIFF('second', PICKUP_DATETIME, DROPOFF_DATETIME) / 3600.0))\n",
    "            END AS AVG_SPEED_MPH,\n",
    "            CASE \n",
    "                WHEN FARE_AMOUNT IS NULL OR FARE_AMOUNT <= 0 THEN NULL\n",
    "                WHEN TIP_AMOUNT IS NULL THEN NULL\n",
    "                ELSE (TIP_AMOUNT / FARE_AMOUNT) * 100.0\n",
    "            END AS TIP_PCT,\n",
    "            \n",
    "            -- Lineage\n",
    "            RUN_ID,\n",
    "            INGESTED_AT_UTC,\n",
    "            SERVICE_TYPE AS SOURCE_SERVICE,\n",
    "            SOURCE_YEAR,\n",
    "            SOURCE_MONTH\n",
    "            \n",
    "        FROM CLEAN.UNIFIED_TRIPS\n",
    "        WHERE SOURCE_YEAR = {TEST_YEAR}\n",
    "          AND SOURCE_MONTH = {TEST_MONTH}\n",
    "          AND SERVICE_TYPE = '{TEST_SERVICE}'\n",
    "          AND PICKUP_DATETIME IS NOT NULL \n",
    "          AND DROPOFF_DATETIME IS NOT NULL\n",
    "          AND PULOCATIONID IS NOT NULL\n",
    "          AND DOLOCATIONID IS NOT NULL\n",
    "        \n",
    "        QUALIFY ROW_NUMBER() OVER (\n",
    "            PARTITION BY PICKUP_DATETIME, DROPOFF_DATETIME, PULOCATIONID, DOLOCATIONID, VENDORID\n",
    "            ORDER BY INGESTED_AT_UTC DESC\n",
    "        ) = 1\n",
    "    )\n",
    ") AS source\n",
    "ON target.TRIP_ID = source.TRIP_ID\n",
    "WHEN MATCHED THEN\n",
    "    UPDATE SET\n",
    "        target.PICKUP_DATETIME = source.PICKUP_DATETIME,\n",
    "        target.DROPOFF_DATETIME = source.DROPOFF_DATETIME,\n",
    "        target.PICKUP_DATE = source.PICKUP_DATE,\n",
    "        target.PICKUP_HOUR = source.PICKUP_HOUR,\n",
    "        target.DROPOFF_DATE = source.DROPOFF_DATE,\n",
    "        target.DROPOFF_HOUR = source.DROPOFF_HOUR,\n",
    "        target.DAY_OF_WEEK = source.DAY_OF_WEEK,\n",
    "        target.MONTH = source.MONTH,\n",
    "        target.YEAR = source.YEAR,\n",
    "        target.PU_LOCATION_ID = source.PU_LOCATION_ID,\n",
    "        target.PU_ZONE = source.PU_ZONE,\n",
    "        target.PU_BOROUGH = source.PU_BOROUGH,\n",
    "        target.DO_LOCATION_ID = source.DO_LOCATION_ID,\n",
    "        target.DO_ZONE = source.DO_ZONE,\n",
    "        target.DO_BOROUGH = source.DO_BOROUGH,\n",
    "        target.SERVICE_TYPE = source.SERVICE_TYPE,\n",
    "        target.VENDOR_ID = source.VENDOR_ID,\n",
    "        target.VENDOR_NAME = source.VENDOR_NAME,\n",
    "        target.RATE_CODE_ID = source.RATE_CODE_ID,\n",
    "        target.RATE_CODE_DESC = source.RATE_CODE_DESC,\n",
    "        target.PAYMENT_TYPE = source.PAYMENT_TYPE,\n",
    "        target.PAYMENT_TYPE_DESC = source.PAYMENT_TYPE_DESC,\n",
    "        target.TRIP_TYPE = source.TRIP_TYPE,\n",
    "        target.TRIP_TYPE_DESC = source.TRIP_TYPE_DESC,\n",
    "        target.PASSENGER_COUNT = source.PASSENGER_COUNT,\n",
    "        target.TRIP_DISTANCE = source.TRIP_DISTANCE,\n",
    "        target.STORE_AND_FWD_FLAG = source.STORE_AND_FWD_FLAG,\n",
    "        target.FARE_AMOUNT = source.FARE_AMOUNT,\n",
    "        target.EXTRA = source.EXTRA,\n",
    "        target.MTA_TAX = source.MTA_TAX,\n",
    "        target.TIP_AMOUNT = source.TIP_AMOUNT,\n",
    "        target.TOLLS_AMOUNT = source.TOLLS_AMOUNT,\n",
    "        target.IMPROVEMENT_SURCHARGE = source.IMPROVEMENT_SURCHARGE,\n",
    "        target.CONGESTION_SURCHARGE = source.CONGESTION_SURCHARGE,\n",
    "        target.AIRPORT_FEE = source.AIRPORT_FEE,\n",
    "        target.TOTAL_AMOUNT = source.TOTAL_AMOUNT,\n",
    "        target.TRIP_DURATION_MIN = source.TRIP_DURATION_MIN,\n",
    "        target.AVG_SPEED_MPH = source.AVG_SPEED_MPH,\n",
    "        target.TIP_PCT = source.TIP_PCT,\n",
    "        target.RUN_ID = source.RUN_ID,\n",
    "        target.INGESTED_AT_UTC = source.INGESTED_AT_UTC,\n",
    "        target.SOURCE_SERVICE = source.SOURCE_SERVICE,\n",
    "        target.SOURCE_YEAR = source.SOURCE_YEAR,\n",
    "        target.SOURCE_MONTH = source.SOURCE_MONTH\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (\n",
    "        TRIP_ID,\n",
    "        PICKUP_DATETIME, DROPOFF_DATETIME, PICKUP_DATE, PICKUP_HOUR,\n",
    "        DROPOFF_DATE, DROPOFF_HOUR, DAY_OF_WEEK, MONTH, YEAR,\n",
    "        PU_LOCATION_ID, PU_ZONE, PU_BOROUGH,\n",
    "        DO_LOCATION_ID, DO_ZONE, DO_BOROUGH,\n",
    "        SERVICE_TYPE, VENDOR_ID, VENDOR_NAME,\n",
    "        RATE_CODE_ID, RATE_CODE_DESC,\n",
    "        PAYMENT_TYPE, PAYMENT_TYPE_DESC,\n",
    "        TRIP_TYPE, TRIP_TYPE_DESC,\n",
    "        PASSENGER_COUNT, TRIP_DISTANCE, STORE_AND_FWD_FLAG,\n",
    "        FARE_AMOUNT, EXTRA, MTA_TAX, TIP_AMOUNT, TOLLS_AMOUNT,\n",
    "        IMPROVEMENT_SURCHARGE, CONGESTION_SURCHARGE, AIRPORT_FEE, TOTAL_AMOUNT,\n",
    "        TRIP_DURATION_MIN, AVG_SPEED_MPH, TIP_PCT,\n",
    "        RUN_ID, INGESTED_AT_UTC, SOURCE_SERVICE, SOURCE_YEAR, SOURCE_MONTH\n",
    "    )\n",
    "    VALUES (\n",
    "        source.TRIP_ID,\n",
    "        source.PICKUP_DATETIME, source.DROPOFF_DATETIME, source.PICKUP_DATE, source.PICKUP_HOUR,\n",
    "        source.DROPOFF_DATE, source.DROPOFF_HOUR, source.DAY_OF_WEEK, source.MONTH, source.YEAR,\n",
    "        source.PU_LOCATION_ID, source.PU_ZONE, source.PU_BOROUGH,\n",
    "        source.DO_LOCATION_ID, source.DO_ZONE, source.DO_BOROUGH,\n",
    "        source.SERVICE_TYPE, source.VENDOR_ID, source.VENDOR_NAME,\n",
    "        source.RATE_CODE_ID, source.RATE_CODE_DESC,\n",
    "        source.PAYMENT_TYPE, source.PAYMENT_TYPE_DESC,\n",
    "        source.TRIP_TYPE, source.TRIP_TYPE_DESC,\n",
    "        source.PASSENGER_COUNT, source.TRIP_DISTANCE, source.STORE_AND_FWD_FLAG,\n",
    "        source.FARE_AMOUNT, source.EXTRA, source.MTA_TAX, source.TIP_AMOUNT, source.TOLLS_AMOUNT,\n",
    "        source.IMPROVEMENT_SURCHARGE, source.CONGESTION_SURCHARGE, source.AIRPORT_FEE, source.TOTAL_AMOUNT,\n",
    "        source.TRIP_DURATION_MIN, source.AVG_SPEED_MPH, source.TIP_PCT,\n",
    "        source.RUN_ID, source.INGESTED_AT_UTC, source.SOURCE_SERVICE, source.SOURCE_YEAR, source.SOURCE_MONTH\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(merge_sql)\n",
    "\n",
    "# 3. Contar filas despues del MERGE\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM ANALYTICS.OBT_TRIPS\n",
    "    WHERE SOURCE_YEAR = {TEST_YEAR}\n",
    "      AND SOURCE_MONTH = {TEST_MONTH}\n",
    "      AND SOURCE_SERVICE = '{TEST_SERVICE}'\n",
    "\"\"\")\n",
    "count_after = cursor.fetchone()[0]\n",
    "print(f\"Despues de UPSERT: {count_after:,} filas para {TEST_SERVICE} {TEST_YEAR}-{TEST_MONTH:02d}\")\n",
    "\n",
    "# 4. Verificar idempotencia\n",
    "print(\"\\n--- Resultado de idempotencia ---\")\n",
    "if count_before == count_after:\n",
    "    print(f\"IDEMPOTENCIA VERIFICADA: {count_before:,} = {count_after:,}\")\n",
    "    print(\"El MERGE actualizo filas existentes sin duplicar.\")\n",
    "else:\n",
    "    diff = count_after - count_before\n",
    "    print(f\"Diferencia detectada: +{diff:,} filas\")\n",
    "    print(\"Esto puede ser normal si hubo nuevos datos en CLEAN.UNIFIED_TRIPS\")\n",
    "\n",
    "# Calcular tiempo transcurrido\n",
    "elapsed_seconds = int(time.time() - start_time)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\nPrueba completada en {elapsed_seconds} segundos.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "396eba5e-fc67-4831-b045-058f65d5a41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VERIFICACIÓN FINAL DE ESTRUCTURA\n",
      "================================================================================\n",
      "\n",
      "Columnas en OBT_TRIPS:\n",
      "--------------------------------------------------------------------------------\n",
      " 1. TRIP_ID                        TEXT                 Nullable: YES\n",
      " 2. PICKUP_DATETIME                TIMESTAMP_NTZ        Nullable: YES\n",
      " 3. DROPOFF_DATETIME               TIMESTAMP_NTZ        Nullable: YES\n",
      " 4. PICKUP_DATE                    DATE                 Nullable: YES\n",
      " 5. PICKUP_HOUR                    NUMBER               Nullable: YES\n",
      " 6. DROPOFF_DATE                   DATE                 Nullable: YES\n",
      " 7. DROPOFF_HOUR                   NUMBER               Nullable: YES\n",
      " 8. DAY_OF_WEEK                    NUMBER               Nullable: YES\n",
      " 9. MONTH                          NUMBER               Nullable: YES\n",
      "10. YEAR                           NUMBER               Nullable: YES\n",
      "11. PU_LOCATION_ID                 NUMBER               Nullable: YES\n",
      "12. PU_ZONE                        TEXT                 Nullable: YES\n",
      "13. PU_BOROUGH                     TEXT                 Nullable: YES\n",
      "14. DO_LOCATION_ID                 NUMBER               Nullable: YES\n",
      "15. DO_ZONE                        TEXT                 Nullable: YES\n",
      "16. DO_BOROUGH                     TEXT                 Nullable: YES\n",
      "17. SERVICE_TYPE                   TEXT                 Nullable: YES\n",
      "18. VENDOR_ID                      NUMBER               Nullable: YES\n",
      "19. VENDOR_NAME                    TEXT                 Nullable: YES\n",
      "20. RATE_CODE_ID                   FLOAT                Nullable: YES\n",
      "21. RATE_CODE_DESC                 TEXT                 Nullable: YES\n",
      "22. PAYMENT_TYPE                   NUMBER               Nullable: YES\n",
      "23. PAYMENT_TYPE_DESC              TEXT                 Nullable: YES\n",
      "24. TRIP_TYPE                      NUMBER               Nullable: YES\n",
      "25. TRIP_TYPE_DESC                 TEXT                 Nullable: YES\n",
      "26. PASSENGER_COUNT                FLOAT                Nullable: YES\n",
      "27. TRIP_DISTANCE                  FLOAT                Nullable: YES\n",
      "28. STORE_AND_FWD_FLAG             TEXT                 Nullable: YES\n",
      "29. FARE_AMOUNT                    FLOAT                Nullable: YES\n",
      "30. EXTRA                          FLOAT                Nullable: YES\n",
      "31. MTA_TAX                        FLOAT                Nullable: YES\n",
      "32. TIP_AMOUNT                     FLOAT                Nullable: YES\n",
      "33. TOLLS_AMOUNT                   FLOAT                Nullable: YES\n",
      "34. IMPROVEMENT_SURCHARGE          FLOAT                Nullable: YES\n",
      "35. CONGESTION_SURCHARGE           FLOAT                Nullable: YES\n",
      "36. AIRPORT_FEE                    FLOAT                Nullable: YES\n",
      "37. TOTAL_AMOUNT                   FLOAT                Nullable: YES\n",
      "38. TRIP_DURATION_MIN              FLOAT                Nullable: YES\n",
      "39. AVG_SPEED_MPH                  FLOAT                Nullable: YES\n",
      "40. TIP_PCT                        FLOAT                Nullable: YES\n",
      "41. RUN_ID                         NUMBER               Nullable: YES\n",
      "42. INGESTED_AT_UTC                TIMESTAMP_NTZ        Nullable: YES\n",
      "43. SOURCE_SERVICE                 TEXT                 Nullable: YES\n",
      "44. SOURCE_YEAR                    NUMBER               Nullable: YES\n",
      "45. SOURCE_MONTH                   NUMBER               Nullable: YES\n",
      "\n",
      "Total de filas: 889,971,027\n",
      "Total de columnas: 45\n",
      "\n",
      "================================================================================\n",
      "NOTEBOOK 03_CONSTRUCCION_OBT.IPYNB COMPLETADO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verificar la tabla OBT_TRIPS.\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VERIFICACIÓN FINAL DE ESTRUCTURA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.environ[\"SNOWFLAKE_USER\"],\n",
    "    password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "    account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "    database=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    role=os.environ[\"SNOWFLAKE_ROLE\"]\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Contar columnas\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "    WHERE TABLE_SCHEMA = 'ANALYTICS' \n",
    "      AND TABLE_NAME = 'OBT_TRIPS'\n",
    "\"\"\")\n",
    "col_count = cursor.fetchone()[0]\n",
    "\n",
    "# Listar columnas\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE\n",
    "    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "    WHERE TABLE_SCHEMA = 'ANALYTICS' \n",
    "      AND TABLE_NAME = 'OBT_TRIPS'\n",
    "    ORDER BY ORDINAL_POSITION\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nColumnas en OBT_TRIPS:\")\n",
    "print(\"-\" * 80)\n",
    "for i, row in enumerate(cursor.fetchall(), 1):\n",
    "    print(f\"{i:2d}. {row[0]:<30} {row[1]:<20} Nullable: {row[2]}\")\n",
    "\n",
    "# Verificar conteo de filas\n",
    "cursor.execute(\"SELECT COUNT(*) FROM ANALYTICS.OBT_TRIPS\")\n",
    "row_count = cursor.fetchone()[0]\n",
    "print(f\"\\nTotal de filas: {row_count:,}\")\n",
    "print(f\"Total de columnas: {col_count}\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NOTEBOOK 03_CONSTRUCCION_OBT.IPYNB COMPLETADO\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
